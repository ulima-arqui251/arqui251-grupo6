# 0.10. Temas Individuales por Integrante - Parte 2 (Informes)
- [Volver al índice](/0/0.md)

## Integrantes 01: Rodrigo De los Ríos  

### Sharding y Particionado Horizontal para Escalabilidad

#### Introducción

En el contexto actual de aplicaciones web de gran escala, la gestión eficiente de grandes volúmenes de datos se ha convertido en un desafío crítico. El **sharding** o **particionado horizontal** emerge como una solución fundamental para abordar los límites de escalabilidad en bases de datos tradicionales.

#### Marco Teórico

##### Definición de Sharding

El **sharding** es una técnica de escalabilidad horizontal que consiste en dividir una base de datos en fragmentos más pequeños llamados **shards**. Cada shard contiene un subconjunto de los datos totales y se almacena en servidores independientes, permitiendo el procesamiento paralelo de consultas y operaciones de escritura.

A diferencia del particionado vertical, que divide las tablas por columnas, el **particionado horizontal divide los datos por filas o registros completos**, utilizando criterios como identificadores de usuario, ubicación geográfica o rangos de fechas.

![Arquitectura Sharding](./assets/rd_01.png)

##### Fundamentos Técnicos

El sharding se basa en los siguientes principios:

- **Distribución de datos**: Los registros se distribuyen entre múltiples nodos según una función de particionado
- **Paralelización**: Las consultas pueden ejecutarse simultáneamente en múltiples shards
- **Independencia**: Cada shard opera como una unidad autónoma
- **Escalabilidad**: Se pueden agregar nuevos shards dinámicamente

#### Análisis Comparativo

##### Estrategias de Escalabilidad

| Estrategia | Descripción | Ventajas | Limitaciones |
|------------|-------------|----------|--------------|
| **Escalado Vertical** | Mejora de hardware en un solo nodo | Simplicidad de implementación | Límite físico del hardware |
| **Replicación** | Copias de datos entre nodos | Mejora en consultas de lectura | No optimiza escrituras |
| **Sharding** | División horizontal de datos | Escalabilidad ilimitada | Complejidad arquitectónica |

![Arquitectura Sharding](./assets/rd_02.jpeg)

##### Ventajas del Sharding

- **Escalabilidad horizontal**: Capacidad de agregar recursos de forma dinámica
- **Rendimiento mejorado**: Reducción de latencia mediante distribución de carga
- **Tolerancia a fallos**: Aislamiento de errores por shard
- **Optimización de recursos**: Mejor utilización del hardware disponible

##### Desafíos y Limitaciones

- **Complejidad arquitectónica**: Requiere diseño cuidadoso de la estrategia de particionado
- **Consultas distribuidas**: Dificultad para realizar joins y agregaciones globales
- **Balanceamiento de carga**: Necesidad de redistribuir datos ante cambios en patrones de uso
- **Consistencia**: Mantenimiento de integridad referencial entre shards

![Arquitectura Sharding](./assets/rd_03.png)

#### Casos de Uso en la Industria

##### Aplicaciones Reales

- **Redes Sociales**: Facebook y Twitter utilizan sharding basado en ID de usuario
- **E-commerce**: Amazon implementa particionado por categoría de producto y región
- **Streaming**: Netflix emplea sharding geográfico para optimizar la entrega de contenido
- **Gaming**: Plataformas como Steam utilizan sharding por región y servidor


##### Criterios de Particionado

Los criterios más comunes para el sharding incluyen:

- **Hash-based**: Distribución basada en funciones hash del ID
- **Range-based**: Particionado por rangos de valores
- **Directory-based**: Uso de un servicio de directorio para mapear datos
- **Geographic**: Distribución basada en ubicación geográfica

#### Implementación Práctica

##### Arquitectura del Sistema Demo

Para demostrar los conceptos teóricos, se desarrolló un sistema de demostración con las siguientes características:

- **Backend**: Node.js con Express.js
- **Base de datos**: MongoDB con 2 shards independientes
- **Containerización**: Docker Compose para orquestación
- **Interfaz**: Frontend web para interacción con el usuario

![Arquitectura Sharding](./assets/rd_04.png)

##### Lógica de Enrutamiento

El sistema implementa una estrategia de sharding basada en hash simple:

```javascript
function getShard(userId) {
    return userId % 2 === 0 ? shard0 : shard1;
}
```

Esta función determina el shard destino basándose en la paridad del ID de usuario, garantizando una distribución equilibrada.

##### Componentes del Sistema

###### Configuración de Docker

```yaml
version: '3.8'
services:
  shard0:
    image: mongo:latest
    container_name: shard0
    ports:
      - "27017:27017"
    volumes:
      - ./data/shard0:/data/db

  shard1:
    image: mongo:latest
    container_name: shard1
    ports:
      - "27018:27017"
    volumes:
      - ./data/shard1:/data/db
```

###### Backend API

El backend expone los siguientes endpoints:

- `POST /posts`: Creación de nuevos posts
- `GET /posts/:userId`: Consulta de posts por usuario
- `GET /stats`: Estadísticas de distribución por shard
- `POST /simulate`: Simulación de carga con datos aleatorios

##### Interfaz de Usuario

La interfaz web proporciona:

- Formulario para creación de posts
- Buscador de posts por ID de usuario
- Generador de datos de prueba
- Visualizador de estadísticas de distribución

![Arquitectura Sharding](./assets/rd_05.png)

#### Resultados y Análisis

##### Métricas de Rendimiento

Durante las pruebas realizadas, se obtuvieron los siguientes resultados:

**Simulación con 100 posts aleatorios:**
- **Shard 0**: 51 posts (51%)
- **Shard 1**: 49 posts (49%)

**Prueba de carga extendida:**
- **Shard 0**: 240 posts (46.7%)
- **Shard 1**: 273 posts (53.3%)

![Arquitectura Sharding](./assets/rd_06.png)

##### Análisis de Distribución

Los resultados demuestran una distribución relativamente equilibrada de los datos entre shards, con una variación menor al 7% en el caso de carga extendida. Esta distribución es aceptable para un sistema de demostración y valida la efectividad del algoritmo de particionado implementado.

##### Consideraciones de Escalabilidad

El sistema demostró capacidad para:

- Manejo simultáneo de múltiples operaciones de escritura
- Consultas independientes por shard
- Generación de estadísticas agregadas
- Simulación de carga realista

#### Instrucciones de Implementación

##### Requisitos del Sistema

- Docker y Docker Compose
- Node.js (versión 14 o superior)
- Puerto 3000 disponible para el backend
- Puertos 27017 y 27018 para MongoDB

##### Pasos de Instalación

1. **Clonar el repositorio**:
   ```bash
   git clone https://github.com/RoudiOlding/sharding_demo.git
   cd sharding-demo
   cd sharding-demo
   ```

2. **Levantar los shards**:
   ```bash
   docker compose up -d
   ```

3. **Iniciar el backend**:
   ```bash
   node src/backend/app.js
   ```

4. **Iniciar el frotnend**:
   ```bash
   npm run dev
   ```
   Abrir `localhost:4321` en el navegador

**{Aquí pon una imagen de comandos de instalación, puedes buscar en Google como "docker nodejs mongodb setup"}**

##### Comandos de Mantenimiento

Para resetear el sistema y limpiar todos los datos:

```bash
docker compose down -v
rm -rf ./data
```
#### Conclusiones

##### Logros del Proyecto

Este proyecto ha demostrado exitosamente:

- La implementación práctica de conceptos de sharding
- La viabilidad de usar herramientas modernas para arquitecturas distribuidas
- La importancia del diseño cuidadoso en sistemas escalables
- La efectividad del particionado horizontal para manejar grandes volúmenes de datos

##### Lecciones Aprendidas

- El sharding manual requiere consideración cuidadosa del algoritmo de particionado
- La distribución equilibrada de datos es crucial para el rendimiento
- La monitorización continua es esencial para detectar desbalances
- La simplicidad en la implementación facilita el mantenimiento y debugging

##### Trabajo Futuro

Para extender este proyecto, se podrían implementar:

- **Rebalanceo automático**: Algoritmos para redistribuir datos dinámicamente
- **Sharding adaptativo**: Ajuste automático del número de shards
- **Monitoreo avanzado**: Métricas detalladas de rendimiento
- **Tolerancia a fallos**: Mecanismos de recuperación automática

#### Referencias

1. **MongoDB Documentation**. *Sharding*. MongoDB Inc. [https://www.mongodb.com/docs/manual/sharding/](https://www.mongodb.com/docs/manual/sharding/)

2. **Vitess Documentation**. *What is Vitess?*. The Vitess Project. [https://vitess.io/docs/overview/what-is-vitess/](https://vitess.io/docs/overview/what-is-vitess/)

3. **GeeksforGeeks**. *Scalability of System*. [https://www.geeksforgeeks.org/scalability-of-system/](https://www.geeksforgeeks.org/scalability-of-system/)

4. **Fowler, M.** *Microservices*. Martin Fowler's Website. [https://martinfowler.com/articles/microservices.html](https://martinfowler.com/articles/microservices.html)

5. **Wikipedia**. *Shard (database architecture)*. [https://en.wikipedia.org/wiki/Shard_(database_architecture)](https://en.wikipedia.org/wiki/Shard_(database_architecture))

6. **Kleppmann, M.** *Designing Data-Intensive Applications*. O'Reilly Media, 2017.

7. **Tanenbaum, A. S., & van Steen, M.** *Distributed Systems: Principles and Paradigms*. Pearson, 2016.

---

**Repositorio del Proyecto**: [https://github.com/roudidev/sharding-demo](https://github.com/RoudiOlding/sharding_demo)


## Integrantes 02: Adrián Duarte
Escriban su desarollo { incluye el enlace a repositorio externo dónde hiciste la demo }

## Integrantes 03: Alejandro Chávez

### Estrategias de Consistencia de Cache

#### Desarrollo Conceptual

En sistemas distribuidos y aplicaciones de alto rendimiento, la caché actúa como una capa intermedia entre los usuarios y el almacenamiento principal, reduciendo la latencia y mejorando los tiempos de respuesta. La consistencia de cache se refiere a la sincronización entre los datos de una cache y el almacenamiento principal. En sistemas distribuidos, mantener esta consistencia es crucial para garantizar que los clientes siempre obtengan datos actualizados, incluso cuando se realizan múltiples operaciones de lectura y escritura al mismo tiempo.

#### Estrategias principales

- Cache-Aside
    - Descripción: La aplicación gestiona directamente la cache. Primero consulta la cache y si no encuentra los datos, los busca en la base de datos principal, los almacena en cache y luego los devuelve.
    - Ventajas: Simple de implementar, eficiente para cargas de trabajo con muchas lecturas.
    - Desventajas: Puede generar inconsistencia temporal entre cache y DB.

- Write-Through
    - Descripción: Cada escritura pasa primero por la cache y luego se escribe sincrónicamente en la base de datos.
    - Ventajas: Garantiza que la cache siempre esté actualizada.
    - Desventajas: Mayor latencia en operaciones de escritura.

- Write-Behind
    - Descripción: Las escrituras se realizan primero en cache y luego, de manera asíncrona, se propagan a la base de datos.
    - Ventajas: Mejor rendimiento en escrituras.
    - Desventajas: Riesgo de pérdida de datos si falla la cache antes de propagar los cambios.

- Refresh-Ahead
    - Descripción: El sistema predice qué datos serán necesitados y los actualiza proactivamente en cache antes de que expire su TTL.
    - Ventajas: Reduce cache misses.
    - Desventajas: Complejidad en la implementación, puede consumir recursos innecesariamente.

#### Consideraciones Técnicas

Al seleccionar una estrategia de consistencia de cache, el primer aspecto técnico a evaluar es el patrón de acceso a los datos. Sistemas con un ratio de 90% lecturas y 10% escrituras se benefician claramente de estrategias como Cache-Aside o Refresh-Ahead, donde se optimiza el acceso rápido a datos frecuentemente leídos. Por el contrario, sistemas con operaciones de escritura intensivas como plataformas de transacciones financieras pueden requerir enfoques como Write-Through para garantizar consistencia inmediata.

Un segundo factor crítico es el tamaño promedio de los datos almacenados en cache. Estrategias como Write-Behind, que mantienen datos en cache por períodos prolongados, pueden ser problemáticas cuando se trabaja con grandes volúmenes de datos que superan la capacidad de la memoria cache disponible. En estos casos, es esencial implementar políticas de evicción eficientes (LRU, LFU) y considerar mecanismos de compresión.

La eficacia de cualquier estrategia depende de una configuración cuidadosa de parámetros técnicos:

- TTL (Time-To-Live):
    - Valores demasiado altos pueden servir datos obsoletos
    - Valores demasiado bajos generan excesivas recargas
    - Solución híbrida: TTL base + invalidación activa para cambios críticos

- Tamaño de Cache:
    - Debe calcularse según el working set de la aplicación
    - Monitorear continuamente la tasa de hits/misses
    - Implementar auto-scaling para cargas variables

- Políticas de Evicción:
    - LRU (Least Recently Used): Ideal para acceso temporalmente localizado
    - LFU (Least Frequently Used): Mejor para patrones de acceso estables
    - FIFO (First In First Out): Simple pero menos eficiente

#### Demo de detección de errores con Sentry
- Asegurarse de usar la rama "master"
https://github.com/AleGCC/demo-cachealejch/tree/master

## Integrantes 04: Angel Alcalá
Escriban su desarollo { incluye el enlace a repositorio externo dónde hiciste la demo }

## Integrantes 05: Erick Valderrama

### Arquitectura Hexagonal: Separación de la lógica de negocio de la infraestructura - Puertos y Adaptadores

#### Desarrollo Conceptual

La Arquitectura Hexagonal, también conocida como Arquitectura de Puertos y Adaptadores, fue propuesta por Alistair Cockburn en 2005 como respuesta a un problema estructural recurrente en el desarrollo de software: la fuerte dependencia de la lógica de negocio respecto a tecnologías o recursos externos, como frameworks web, bases de datos o interfaces gráficas (Cockburn, 2005).

Este patrón propone un enfoque donde la aplicación se organiza desde adentro hacia afuera. Coloca el dominio central (reglas de negocio y entidades) en el núcleo del sistema y conectándolo con el mundo exterior a través de interfaces claramente definidas llamadas puertos y sus implementaciones concretas denominadas adaptadores.

El objetivo central de esta arquitectura es lograr una separación estricta de problemas, asegurar que los elementos de infraestructura cambian con mayor frecuencia no afecten directamente la lógica del negocio. Esta separación permite construir sistemas más modulares, mantenibles, testeables y resistentes a cambios tecnológicos. En palabras de Martin Fowler (2002), “la clave de un buen diseño arquitectónico es aislar las partes que cambian de las que no cambian”.

**¿Cómo funciona?**

En el campo, los puertos son interfaces que definen "contratos" de comunicación que el núcleo de la aplicación necesita para interactuar con servicios externos o exponer funcionalidades. Un ejemplo es que se pueden definir puertos como "guardarCliente()" o "enviarCorreo()". Los adaptadores en cambio son las implementaciones concretas de estos puertos, un adaptador puede utilizar PostgreSQL para persistir datos, otro puede enviar correos mediante una API externa como SendGrid.

A esta inversión de control se le llama Dependency Inversion Principle (DIP), uno de los principios SOLID más importantes en diseño de software. Según este principio, el código de alto nivel (el dominio) no debe depender del código de bajo nivel (como frameworks), sino que ambos deben depender de abstracciones (Martin, 2018).

**¿Cómo se interrelacionan?**

Uno de los aspectos más poderosos de la arquitectura hexagonal es que permite que componentes heterogéneos, como un adaptador web en TypeScript, uno de persistencia en SQL, o incluso uno de línea de comandos en Bash, interactúen sin conflictos con el núcleo de la aplicación. Esta interrelación exitosa es posible gracias a cuatro mecanismos fundamentales: la definición clara de puertos, el uso de interfaces como contratos, y la inversión de dependencias.

1. Contratos de comunicación (puertos).-
El núcleo de la aplicación no conoce los detalles técnicos de los adaptadores, solo conoce lo que espera de ellos, sus productos. Esto se logra mediante interfaces o abstracciones llamadas puertos. Por ejemplo, el dominio puede definir un puerto como *RepositorioDeTareas* que espera un método "guardar(tarea: Tarea): void". No importa si el adaptador implementa esto usando PostgreSQL, MongoDB, una API REST o un archivo plano: mientras respete la firma y comportamiento del puerto, será compatible.

“Los puertos actúan como un contrato de uso: el núcleo sabe qué necesita, no cómo se implementa”
— (Cockburn, 2005)

2. Implementaciones independientes (adaptadores).-
Cada adaptador se encarga de traducir su mundo externo al lenguaje que entiende el dominio. Lo importante es que todos estos adaptadores pueden estar escritos en distintos lenguajes, ejecutarse en distintos contextos o plataformas, y aun así interconectarse sin problemas, siempre que respeten el contrato del puerto. Este desacoplamiento permite desarrollar cada adaptador de forma independiente, incluso en tiempos distintos. Por ejemplo:
- Un adaptador HTTP convierte una petición JSON en un objeto Tarea y llama a crearTarea().
- Un adaptador CLI puede leer datos desde consola, convertirlos y pasarlos al núcleo.
- Un adaptador de base de datos traduce un INSERT SQL a una llamada al puerto de persistencia.

3. Inversión de dependencias.-
Gracias al principio de inversión de dependencias (DIP), el núcleo no depende de ningún adaptador. Es el adaptador quien depende del núcleo. Esto se facilita mediante inyección de dependencias o mecanismos similares, donde el adaptador “registra” su implementación y la conecta con el puerto definido por el dominio. Así, el núcleo solo ve una abstracción, sin saber si lo que está detrás es un servicio en la nube, una función local o una librería externa.

4. Traducción semántica.-
Otro “secreto” clave es que la arquitectura hexagonal enfatiza la responsabilidad de traducción en los bordes del sistema, no en el núcleo. Este se mantiene limpio, sin lógica técnica ni preocupaciones externas. Este aislamiento semántico evita que el núcleo “se contamine” con detalles del mundo exterior, manteniendo su propósito puro y coherente. Esto significa que los adaptadores son los responsables de:

- Validar y transformar los datos de entrada.

- Convertir errores del dominio en códigos HTTP o mensajes CLI.

- Formatear las respuestas para el mundo exterior.

**¿Cómo debe construirse un sistema con arquitectura hexagonal?**

Una de las grandes virtudes de la arquitectura hexagonal es que organiza el desarrollo desde adentro hacia afuera, priorizando la lógica de negocio por encima de los detalles técnicos. Esto no es solo un enfoque estructural, sino también una metodología de trabajo. El flujo de desarrollo recomendado es el siguiente:

1. Desarrollo del Núcleo (Dominio).- 
El primer paso consiste en modelar el dominio de la aplicación, es decir, las entidades, reglas de negocio y casos de uso. No conoce nada del exterior. Por ejemplo, en una aplicación de gestión de tareas, se definirá primero la entidad Tarea con sus reglas (no puede tener una fecha en el pasado, debe tener un título válido, etc.) y los casos de uso como crearTarea() o completarTarea().

2. Definición de Puertos.-
Luego se identifican las interfaces que necesita el núcleo para funcionar o exponer su funcionalidad. Estos puertos funcionan como contratos abstractos: definen qué espera el núcleo sin decir cómo debe hacerse. Por ejemplo, el caso de uso crearTarea() podría depender de un puerto RepositorioDeTareas, que define métodos como guardar(tarea: Tarea) o buscarPorId(id: string). También puede existir un puerto de salida como Notificador, que permite enviar mensajes a otros sistemas.

3. Implementación de Adaptadores
Finalmente, se desarrollan los adaptadores, que son las implementaciones concretas de esos puertos. Un adaptador puede ser lo que sea. Cada adaptador se acopla al dominio, pero el dominio nunca se acopla a los adaptadores. Esto permite que, incluso si se decide cambiar de Express a Fastify, o de PostgreSQL a MongoDB, el núcleo permanezca intacto.

*Este enfoque también permite el desarrollo en paralelo de distintas partes del sistema, ya que los equipos pueden trabajar sobre adaptadores o interfaces gráficas sin necesidad de modificar el dominio.*

**Comparación con arquitecturas tradicionales**

A diferencia del enfoque en capas clásico (Presentation → Application → Domain → Infrastructure), donde las dependencias suelen fluir desde la capa superior hacia la base de datos, en la arquitectura hexagonal la dependencia es invertida: el dominio no conoce ni depende de ninguna tecnología externa. Esta independencia técnica convierte al dominio en una unidad fácilmente testeable, reutilizable y portable entre proyectos.

**Relación con Clean Architecture y DDD**

Este patrón influenció directamente a otras arquitecturas modernas, como la Clean Architecture de Robert C. Martin, y se alinea con los principios del Domain-Driven Design (DDD) propuestos por Eric Evans. En ambas corrientes, la prioridad es resguardar la lógica de negocio frente al ruido de la infraestructura (Evans, 2003; Martin, 2018).

**Ejemplo ilustrativo**

Propongamos una estación de radio como núcleo, como dominio. Esta puede recibir señales de varias fuentes: antena, internet o Bluetooth. Lo importante es que la estación sabe cómo interpretar una señal, pero no es necesario saber de donde viene para que funcione. Las fuentes son adaptadores, y la interfaz para recibir señal es el puerto. Si un día se cambia de antena a internet, la estación sigue funcionando igual. Este es el corazón del enfoque hexagonal: el dominio no se ve afectado por los cambios en los canales de comunicación.

**Aplicaciones prácticas**

La arquitectura hexagonal es especialmente útil en:

- Aplicaciones que requieren larga vida útil o mantenimiento continuo.

- Sistemas orientados a microservicios, donde cada servicio tiene su propio dominio aislado.

- Casos donde se desea desarrollar la lógica de negocio antes que la UI o el backend.

- Proyectos con alta necesidad de pruebas unitarias independientes del entorno.

**Ventajas principales**

- Testabilidad: al estar desacoplado, el núcleo se puede probar sin infraestructura externa.

- Flexibilidad tecnológica: se pueden cambiar bases de datos, frameworks web o APIs sin tocar el dominio.

- Simplicidad conceptual: al dividir explícitamente entre el qué (dominio) y el cómo (adaptadores).

- Claridad de responsabilidades: cada componente tiene una función específica, lo que reduce la complejidad.

#### Limitaciones de la arquitectura hexagonal

Aunque la arquitectura hexagonal ofrece ventajas significativas, también presenta ciertos desafíos y limitaciones que deben ser considerados al adoptarla:

- Curva de aprendizaje inicial: Para equipos no familiarizados con principios como inversión de dependencias, inyección de puertos y separación de capas, la arquitectura puede parecer innecesariamente compleja al principio (Brown, 2016).

- Sobrecarga estructural en proyectos pequeños: En aplicaciones simples o de corta duración, el esfuerzo de crear puertos y adaptadores puede no justificarse, generando más complejidad de la necesaria.

- Mantenimiento de múltiples adaptadores: En sistemas que requieren muchos canales de entrada/salida (REST, CLI, mensajería, etc.), mantener la sincronía entre los adaptadores y el núcleo puede volverse costoso si no se automatiza adecuadamente.

- Testing cruzado: Aunque facilita las pruebas unitarias del dominio, las pruebas de integración entre adaptadores pueden volverse más técnicas, especialmente si hay muchas implementaciones por puerto.

**Casos ideales para aplicar arquitectura hexagonal**

- Sistemas con múltiples interfaces de entrada/salida: Como aplicaciones que ofrecen interfaz web, API REST y línea de comandos en simultáneo.

- Proyectos que usarán diferentes tecnologías a lo largo del tiempo: Por ejemplo, sistemas que inicialmente usan SQLite pero luego migran a PostgreSQL o MongoDB, sin reescribir la lógica del dominio.

- Aplicaciones que deben integrarse con servicios externos: Como pasarelas de pago, servicios de notificación (SMS, email), o APIs de terceros que pueden cambiar con frecuencia.

- Entornos con alta exigencia de pruebas automatizadas: Como sistemas financieros, donde el dominio debe estar probado independientemente de la base de datos o del servidor.

### Implementación del sistema

Se implementó una aplicación de gestión de tareas basada en el patrón de arquitectura hexagonal. El código se organizó en cuatro capas principales:

1. **Dominio (`domain/`)**  
   Contiene la entidad `Tarea`, la cual representa el núcleo del modelo de negocio. Esta entidad define sus propiedades, como título, estado de completado y fecha de creación. Aquí se encapsulan las reglas de negocio independientes de cualquier tecnología externa.

2. **Puertos (`ports/`)**  
   Define las interfaces que el dominio necesita para interactuar con el exterior.  
   - `RepositorioDeTareas`: un puerto que define métodos como `guardar`, `listar`, etc.  
   - `ServicioDeTareas`: caso de uso que utiliza el puerto para operar sobre las tareas. Actúa como la capa de aplicación que orquesta la lógica.

3. **Adaptadores (`adapters/`)**  
   Proveen implementaciones concretas de los puertos.  
   - `repositorio_memoria.py`: guarda las tareas en una lista de Python (modo temporal).  
   - `repositorio_archivo.py`: guarda y carga tareas desde un archivo `.txt`.  
   - `repositorio_sqlite.py`: persiste tareas en una base de datos SQLite.  
   - `api_rest.py`: adaptador de entrada para exponer la lógica mediante FastAPI (REST).  

4. **Configuración Principal (`main.py`)**  
   Permite ejecutar el sistema en dos modos:
   - **Consola** (`s`): interactúa directamente con el servicio desde la línea de comandos.
   - **API REST** (`n`): expone la lógica como endpoints HTTP y genera Swagger UI automáticamente.

Este enfoque permite probar y extender el sistema fácilmente. Por ejemplo, es posible añadir un nuevo adaptador (como una interfaz web o un bot de Telegram) sin modificar el dominio.

---

### Link del Repositorio

https://github.com/DmitriVurb/Arquitectura_Hexagonal.git

#### Referencias

- Brown, S. (2016). *Software Architecture for Developers*. Coding the architecture. Recuperado de https://static.codingthearchitecture.com/sddconf2014-software-architecture-for-developers-extract.pdf 
- Cockburn, A. (2005). *The Hexagonal (Ports & Adapters) Architecture*. Recuperado de https://alistair.cockburn.us/hexagonal-architecture/
- Evans, E. (2003). Domain-Driven Design: Tackling Complexity in the Heart of Software. Addison-Wesley. Recuperado de https://fabiofumarola.github.io/nosql/readingMaterial/Evans03.pdf
- Fowler, M. (2002). *Patterns of Enterprise Application Architecture*. Addison-Wesley. Recuperado de https://dl.ebooksworld.ir/motoman/Patterns%20of%20Enterprise%20Application%20Architecture.pdf
- Martin, R. C. (2018). Clean Architecture: A Craftsman's Guide to Software Structure and Design. Prentice Hall. Recuperado de https://agorism.dev/book/software-architecture/%28Robert%20C.%20Martin%20Series%29%20Robert%20C.%20Martin%20-%20Clean%20Architecture_%20A%20Craftsman%E2%80%99s%20Guide%20to%20Software%20Structure%20and%20Design-Prentice%20Hall%20%282017%29.pdf










