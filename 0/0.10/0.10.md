# 0.10. Temas Individuales por Integrante - Parte 2 (Informes)
- [Volver al √≠ndice](/0/0.md)

## Integrantes 01: Rodrigo De los R√≠os
Escriban su desarollo { incluye el enlace a repositorio externo d√≥nde hiciste la demo }

‚Äî‚Äî Referencia 01: https://www.intersystems.com/es/recursos/sharding-bbdd/

{ hablar de la situaci√≥n actual de los datos masivos, la soluci√≥n que ofrece Sharding, ejemplo f√°cil de c√≥mo funciona shrading (maletas ) }

## Integrantes 02: Adri√°n Duarte
Escriban su desarollo { incluye el enlace a repositorio externo d√≥nde hiciste la demo }

## Integrantes 03: Alejandro Ch√°vez

### Estrategias de Consistencia de Cache

#### Desarrollo Conceptual

En sistemas distribuidos y aplicaciones de alto rendimiento, la cach√© act√∫a como una capa intermedia entre los usuarios y el almacenamiento principal, reduciendo la latencia y mejorando los tiempos de respuesta. La consistencia de cache se refiere a la sincronizaci√≥n entre los datos de una cache y el almacenamiento principal. En sistemas distribuidos, mantener esta consistencia es crucial para garantizar que los clientes siempre obtengan datos actualizados, incluso cuando se realizan m√∫ltiples operaciones de lectura y escritura al mismo tiempo.

#### Estrategias principales

- Cache-Aside
    - Descripci√≥n: La aplicaci√≥n gestiona directamente la cache. Primero consulta la cache y si no encuentra los datos, los busca en la base de datos principal, los almacena en cache y luego los devuelve.
    - Ventajas: Simple de implementar, eficiente para cargas de trabajo con muchas lecturas.
    - Desventajas: Puede generar inconsistencia temporal entre cache y DB.

- Write-Through
    - Descripci√≥n: Cada escritura pasa primero por la cache y luego se escribe sincr√≥nicamente en la base de datos.
    - Ventajas: Garantiza que la cache siempre est√© actualizada.
    - Desventajas: Mayor latencia en operaciones de escritura.

- Write-Behind
    - Descripci√≥n: Las escrituras se realizan primero en cache y luego, de manera as√≠ncrona, se propagan a la base de datos.
    - Ventajas: Mejor rendimiento en escrituras.
    - Desventajas: Riesgo de p√©rdida de datos si falla la cache antes de propagar los cambios.

- Refresh-Ahead
    - Descripci√≥n: El sistema predice qu√© datos ser√°n necesitados y los actualiza proactivamente en cache antes de que expire su TTL.
    - Ventajas: Reduce cache misses.
    - Desventajas: Complejidad en la implementaci√≥n, puede consumir recursos innecesariamente.

#### Consideraciones T√©cnicas

Al seleccionar una estrategia de consistencia de cache, el primer aspecto t√©cnico a evaluar es el patr√≥n de acceso a los datos. Sistemas con un ratio de 90% lecturas y 10% escrituras se benefician claramente de estrategias como Cache-Aside o Refresh-Ahead, donde se optimiza el acceso r√°pido a datos frecuentemente le√≠dos. Por el contrario, sistemas con operaciones de escritura intensivas como plataformas de transacciones financieras pueden requerir enfoques como Write-Through para garantizar consistencia inmediata.

Un segundo factor cr√≠tico es el tama√±o promedio de los datos almacenados en cache. Estrategias como Write-Behind, que mantienen datos en cache por per√≠odos prolongados, pueden ser problem√°ticas cuando se trabaja con grandes vol√∫menes de datos que superan la capacidad de la memoria cache disponible. En estos casos, es esencial implementar pol√≠ticas de evicci√≥n eficientes (LRU, LFU) y considerar mecanismos de compresi√≥n.

La eficacia de cualquier estrategia depende de una configuraci√≥n cuidadosa de par√°metros t√©cnicos:

- TTL (Time-To-Live):
    - Valores demasiado altos pueden servir datos obsoletos
    - Valores demasiado bajos generan excesivas recargas
    - Soluci√≥n h√≠brida: TTL base + invalidaci√≥n activa para cambios cr√≠ticos

- Tama√±o de Cache:
    - Debe calcularse seg√∫n el working set de la aplicaci√≥n
    - Monitorear continuamente la tasa de hits/misses
    - Implementar auto-scaling para cargas variables

- Pol√≠ticas de Evicci√≥n:
    - LRU (Least Recently Used): Ideal para acceso temporalmente localizado
    - LFU (Least Frequently Used): Mejor para patrones de acceso estables
    - FIFO (First In First Out): Simple pero menos eficiente

#### Demo de detecci√≥n de errores con Sentry
- Asegurarse de usar la rama "master"
https://github.com/AleGCC/demo-cachealejch/tree/master

## Integrantes 04: Angel Alcal√°

### Benchmarking de LLMs para Generaci√≥n de C√≥digo

#### Desarrollo Conceptual

Los modelos de lenguaje de gran escala (LLMs, por sus siglas en ingl√©s) se han convertido en herramientas clave para la generaci√≥n autom√°tica de c√≥digo, permitiendo desde el autocompletado hasta la creaci√≥n de funciones complejas a partir de descripciones en lenguaje natural. Dado el amplio abanico de modelos disponibles, el benchmarking o evaluaci√≥n comparativa de estos modelos se vuelve esencial para entender su desempe√±o en tareas espec√≠ficas y tomar decisiones informadas al momento de integrarlos en flujos de trabajo de desarrollo.

El benchmarking de LLMs implica medir su precisi√≥n, eficiencia y utilidad pr√°ctica en contextos reales de programaci√≥n. Esto puede abarcar desde la calidad sint√°ctica y sem√°ntica del c√≥digo generado, hasta el cumplimiento de especificaciones, compatibilidad con lenguajes espec√≠ficos, y la habilidad para depurar errores o completar c√≥digo parcial.

#### Estrategias principales

- **Few-Shot Learning**
    - **Descripci√≥n**: Se proporciona al modelo unos pocos ejemplos como contexto antes de realizar una tarea espec√≠fica de generaci√≥n de c√≥digo.
    - **Ventajas**: Reduce la necesidad de entrenamiento adicional, adaptable a m√∫ltiples dominios.
    - **Desventajas**: Sensible al orden y calidad de los ejemplos; puede ser inconsistente.

- **Zero-Shot Learning**
    - **Descripci√≥n**: El modelo genera c√≥digo a partir de una descripci√≥n sin ejemplos previos, confiando √∫nicamente en su conocimiento preentrenado.
    - **Ventajas**: Ideal para tareas generales; no requiere preparaci√≥n previa.
    - **Desventajas**: Menor precisi√≥n en dominios altamente especializados.

- **Code Completion**
    - **Descripci√≥n**: Eval√∫a la capacidad del modelo para completar bloques de c√≥digo parcialmente escritos, simulando casos de uso reales en editores de texto.
    - **Ventajas**: Muy √∫til para desarrolladores; mejora la productividad.
    - **Desventajas**: Puede producir resultados err√≥neos si el contexto es ambiguo o incompleto.

- **Bug Fixing y Refactoring**
    - **Descripci√≥n**: Se mide la habilidad del modelo para identificar errores y proponer soluciones o mejoras estructurales al c√≥digo.
    - **Ventajas**: Aporta valor en mantenimiento de software.
    - **Desventajas**: Dif√≠cil evaluar objetivamente; algunas sugerencias pueden ser sint√°cticamente correctas pero funcionalmente err√≥neas.

#### Consideraciones T√©cnicas

Al seleccionar un LLM para generaci√≥n de c√≥digo, el primer aspecto t√©cnico a considerar es el **lenguaje de programaci√≥n objetivo**. Algunos modelos est√°n optimizados para lenguajes como Python o JavaScript, mientras que su rendimiento disminuye con lenguajes menos comunes o altamente tipados como Rust o Haskell.

Otro factor determinante es el **tama√±o del contexto** que el modelo puede manejar. Modelos como GPT-4 o Claude-3 permiten trabajar con ventanas de contexto extendidas, √∫tiles en proyectos con m√∫ltiples dependencias y estructuras complejas.

La evaluaci√≥n debe realizarse con m√©tricas objetivas y subjetivas:

- **Exactitud Sem√°ntica**:
    - ¬øEl c√≥digo cumple con la especificaci√≥n solicitada?
    - ¬øProduce el resultado esperado al ser ejecutado?

- **Calidad Sint√°ctica**:
    - ¬øEl c√≥digo es v√°lido seg√∫n el compilador/int√©rprete?
    - ¬øSigue buenas pr√°cticas de estilo?

- **Tiempo de Respuesta y Costo Computacional**:
    - Importante en aplicaciones de uso intensivo o en tiempo real.
    - Se deben balancear latencia, costo por token y tama√±o del modelo.

- **Tolerancia a Errores**:
    - ¬øEl modelo entiende y corrige entradas incompletas o ambiguas?
    - ¬øEs robusto frente a instrucciones contradictorias?

#### Herramientas y Frameworks de Evaluaci√≥n

- **HumanEval**:
    - Conjunto de pruebas creado por OpenAI para medir la capacidad de resoluci√≥n de problemas mediante generaci√≥n de c√≥digo en Python.

- **CodeXGLUE**:
    - Benchmark open-source que eval√∫a m√∫ltiples tareas como generaci√≥n, traducci√≥n y clasificaci√≥n de c√≥digo.

- **MBPP (Mostly Basic Programming Problems)**:
    - Eval√∫a el rendimiento de modelos en problemas simples pero pr√°cticos, ideales para modelar tareas de principiantes o automatizaci√≥n b√°sica.

- **BigCode y EvalPlus**:
    - Enfocados en evaluaci√≥n reproducible, escalable y segura de modelos de c√≥digo abierto y cerrado.

---

El benchmarking riguroso y bien dise√±ado no solo permite identificar fortalezas y debilidades de los LLMs, sino que tambi√©n orienta su uso hacia escenarios m√°s eficientes y realistas en entornos de desarrollo profesional.

#### Demo del c√≥digo

La presente demo tiene como finalidad realizar un benchmark b√°sico de modelos de lenguaje entrenados para la generaci√≥n de c√≥digo, usando modelos open-source gratuitos como Hugging Face. Para ser mas espec√≠ficos, se evaluar√° el modelo StarCoder, el cual es dise√±ado para tareas de programaci√≥n.

###### Requisitos previos

Primero, se debe instalar transformers torch en la terminal para la funcionalidad del c√≥digo

```
pip install transformers torch
```
Posteriormente se deber√° implementar el siguiente c√≥digo en cualquier
IDE

```python
from transformers import pipeline
import time

# Cargar modelo gratuito
print("üîÑ Cargando modelo...")
generator = pipeline("text-generation", model="Salesforce/codegen-350M-multi")
print("‚úÖ Modelo cargado.\n")

# Dataset de evaluaci√≥n
benchmarks = [
    {
        "prompt": "Escribe una funci√≥n en Python que sume dos n√∫meros",
        "expected": "def suma(a, b):\n    return a + b"
    },
    {
        "prompt": "Crea una funci√≥n para calcular el factorial de un n√∫mero",
        "expected": "def factorial(n):\n    if n == 0:\n        return 1\n    return n * factorial(n - 1)"
    },
    {
        "prompt": "Haz una funci√≥n que determine si un n√∫mero es par",
        "expected": "def es_par(n):\n    return n % 2 == 0"
    }
]

# Funci√≥n simple de comparaci√≥n
def exact_match(expected, generated):
    expected_clean = expected.strip().replace(" ", "").lower()
    generated_clean = generated.strip().replace(" ", "").lower()
    return expected_clean in generated_clean

# Evaluaci√≥n
aciertos = 0
total = len(benchmarks)

for i, bench in enumerate(benchmarks, start=1):
    print(f"üîç [{i}/{total}] Prompt: {bench['prompt']}")
    start = time.time()
    response = generator(bench['prompt'], max_new_tokens=100, do_sample=False)[0]['generated_text']
    end = time.time()

    # Limpiar solo el bloque de c√≥digo generado
    generated_code = response.split(bench['prompt'])[-1].strip()
    
    # Evaluar
    match = exact_match(bench["expected"], generated_code)
    resultado = "‚úÖ Correcto" if match else "‚ùå Incorrecto"
    print(f"Resultado: {resultado}")
    print("C√≥digo generado:\n", generated_code)
    print(f"‚è±Ô∏è Tiempo de respuesta: {round(end - start, 2)}s\n")

    if match:
        aciertos += 1

# Resumen
print("üìä Resultado final del benchmark:")
print(f"Aciertos: {aciertos}/{total}")
print(f"Precisi√≥n: {round((aciertos / total) * 100, 2)}%")

```

El presente c√≥digo carga el modelo codegen-350M-multi de Hugging Face, un generador de c√≥digo abierto entrenado por Salesforce. Luego, genera c√≥digo a partir de una instrucci√≥n en lenguaje natural utilizando un pipeline de generaci√≥n de texto. Finalmente, imprime el c√≥digo generado por el modelo.



## Integrantes 05: Erick Valderrama
Escriban su desarollo { incluye el enlace a repositorio externo d√≥nde hiciste la demo }
