# 0.10. Temas Individuales por Integrante - Parte 2 (Informes)
- [Volver al índice](/0/0.md)

## Integrantes 01: Rodrigo De los Ríos
Escriban su desarollo { incluye el enlace a repositorio externo dónde hiciste la demo }

—— Referencia 01: https://www.intersystems.com/es/recursos/sharding-bbdd/

{ hablar de la situación actual de los datos masivos, la solución que ofrece Sharding, ejemplo fácil de cómo funciona shrading (maletas ) }

## Integrantes 02: Adrián Duarte
Escriban su desarollo { incluye el enlace a repositorio externo dónde hiciste la demo }

## Integrantes 03: Alejandro Chávez

### Estrategias de Consistencia de Cache

#### Desarrollo Conceptual

En sistemas distribuidos y aplicaciones de alto rendimiento, la caché actúa como una capa intermedia entre los usuarios y el almacenamiento principal, reduciendo la latencia y mejorando los tiempos de respuesta. La consistencia de cache se refiere a la sincronización entre los datos de una cache y el almacenamiento principal. En sistemas distribuidos, mantener esta consistencia es crucial para garantizar que los clientes siempre obtengan datos actualizados, incluso cuando se realizan múltiples operaciones de lectura y escritura al mismo tiempo.

#### Estrategias principales

- Cache-Aside
    - Descripción: La aplicación gestiona directamente la cache. Primero consulta la cache y si no encuentra los datos, los busca en la base de datos principal, los almacena en cache y luego los devuelve.
    - Ventajas: Simple de implementar, eficiente para cargas de trabajo con muchas lecturas.
    - Desventajas: Puede generar inconsistencia temporal entre cache y DB.

- Write-Through
    - Descripción: Cada escritura pasa primero por la cache y luego se escribe sincrónicamente en la base de datos.
    - Ventajas: Garantiza que la cache siempre esté actualizada.
    - Desventajas: Mayor latencia en operaciones de escritura.

- Write-Behind
    - Descripción: Las escrituras se realizan primero en cache y luego, de manera asíncrona, se propagan a la base de datos.
    - Ventajas: Mejor rendimiento en escrituras.
    - Desventajas: Riesgo de pérdida de datos si falla la cache antes de propagar los cambios.

- Refresh-Ahead
    - Descripción: El sistema predice qué datos serán necesitados y los actualiza proactivamente en cache antes de que expire su TTL.
    - Ventajas: Reduce cache misses.
    - Desventajas: Complejidad en la implementación, puede consumir recursos innecesariamente.

#### Consideraciones Técnicas

Al seleccionar una estrategia de consistencia de cache, el primer aspecto técnico a evaluar es el patrón de acceso a los datos. Sistemas con un ratio de 90% lecturas y 10% escrituras se benefician claramente de estrategias como Cache-Aside o Refresh-Ahead, donde se optimiza el acceso rápido a datos frecuentemente leídos. Por el contrario, sistemas con operaciones de escritura intensivas como plataformas de transacciones financieras pueden requerir enfoques como Write-Through para garantizar consistencia inmediata.

Un segundo factor crítico es el tamaño promedio de los datos almacenados en cache. Estrategias como Write-Behind, que mantienen datos en cache por períodos prolongados, pueden ser problemáticas cuando se trabaja con grandes volúmenes de datos que superan la capacidad de la memoria cache disponible. En estos casos, es esencial implementar políticas de evicción eficientes (LRU, LFU) y considerar mecanismos de compresión.

La eficacia de cualquier estrategia depende de una configuración cuidadosa de parámetros técnicos:

- TTL (Time-To-Live):
    - Valores demasiado altos pueden servir datos obsoletos
    - Valores demasiado bajos generan excesivas recargas
    - Solución híbrida: TTL base + invalidación activa para cambios críticos

- Tamaño de Cache:
    - Debe calcularse según el working set de la aplicación
    - Monitorear continuamente la tasa de hits/misses
    - Implementar auto-scaling para cargas variables

- Políticas de Evicción:
    - LRU (Least Recently Used): Ideal para acceso temporalmente localizado
    - LFU (Least Frequently Used): Mejor para patrones de acceso estables
    - FIFO (First In First Out): Simple pero menos eficiente

#### Demo de detección de errores con Sentry
- Asegurarse de usar la rama "master"
https://github.com/AleGCC/demo-cachealejch/tree/master

## Integrantes 04: Angel Alcalá
Escriban su desarollo { incluye el enlace a repositorio externo dónde hiciste la demo }

## Integrantes 05: Erick Valderrama
Escriban su desarollo { incluye el enlace a repositorio externo dónde hiciste la demo }
