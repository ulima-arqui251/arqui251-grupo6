# 5.4. Rendimiento

## Módulo 01: Gestión de Usuarios
### Escenario 1

| **Cod Escenario** | **Atributo de Calidad** | **Estímulo**                           | **Fuente del Estímulo** | **Artefacto**                  | **Entorno**                         | **Respuesta**                                                | **Medida de Respuesta**                             |
|------------------|-------------------------|----------------------------------------|-------------------------|--------------------------------|-------------------------------------|-------------------------------------------------------------|-----------------------------------------------------|
| ESC-04 | Eficiencia | 15 registros simultáneos | Sistema | Node.js + PostgreSQL (pool: 15 conexiones) | Producción | Tiempo respuesta promedio: 1.2s | 95% requests <1.5s (k6 con 100 VUs) |

- Elección entre Pool de conexiones optimizado en Sequelize y Implementación de cola asincrónica con BullMQ

### Táctica Elegida
Pool de conexiones optimizado en Sequelize

**Contexto:**  
El registro de usuarios es uno de los puntos de mayor tráfico en el Módulo 1. En campañas de lanzamiento, la plataforma puede recibir múltiples formularios al mismo tiempo. Esto puede provocar cuellos de botella en la conexión a la base de datos. El backend utiliza Node.js, Sequelize y PostgreSQL, y está desplegado en contenedores escalables por Kubernetes.

**Alternativas:**
1. **Alternativa 1: Pool de conexiones optimizado en Sequelize**
     - Configurar max, min y idle apropiadamente en el pool.
     - Permite reutilizar conexiones a la base de datos.
     - Escalable horizontalmente con réplicas backend.

2. **Alternativa 2: Implementación de cola asincrónica con BullMQ**
     - Las peticiones de registro son encoladas.
     - Un worker procesa los registros uno por uno.
     - Aumenta la tolerancia a picos altos de tráfico.
     
**Criterios de elección:**
- **Velocidad de respuesta:** El pool responde en tiempo real; la cola introduce latencia controlada
- **Escalabilidad horizontal:** Pool más simple de escalar; la cola requiere workers dedicados
- **Tamaño del tráfico esperado:** El pool cubre la demanda media; BullMQ es mejor para grandes picos

**Decisión:**
Pool de conexiones optimizado en Sequelize

**Sustento:**
La demanda esperada (15 usuarios simultáneos) se maneja eficientemente con un pool correctamente configurado. Sequelize permite controlar este comportamiento fácilmente, y se alinea con las decisiones existentes del stack (sin introducir complejidad adicional como colas o workers). Además, Kubernetes facilita el escalamiento si se requiere mayor capacidad en el futuro.

### Escenario 2

| **Cod Escenario** | **Atributo de Calidad** | **Estímulo**                           | **Fuente del Estímulo** | **Artefacto**                  | **Entorno**                         | **Respuesta**                                                | **Medida de Respuesta**                             |
|------------------|-------------------------|----------------------------------------|-------------------------|--------------------------------|-------------------------------------|-------------------------------------------------------------|-----------------------------------------------------|
| ESC-13 | Eficiencia | Fallo servicio géneros musicales | API externa | Redis Cache (TTL 1h) | Producción | Respuesta con datos cacheados + timestamp | 70% reducción llamadas fallidas (Prometheus) |

- Elección entre Caching con Redis y TTL de 1 hora y Replicación local diaria de la lista de géneros

### Táctica Elegida
Caching con Redis y TTL de 1 hora

**Contexto:**  
Durante el registro de usuarios o configuración inicial del perfil, se solicita una lista de géneros musicales (usada también en recomendaciones y búsquedas). Esta lista proviene de una API externa, por lo que puede fallar o ser lenta. Para mejorar el rendimiento y asegurar una experiencia estable, se requiere una táctica de caching robusta y sencilla.

**Alternativas:**
1. **Alternativa 1: Caching con Redis y TTL de 1 hora**
     - Cada vez que se solicitan géneros, se consulta Redis primero.
     - Si no existe en caché, se obtiene desde la API externa y se guarda.
     - Reduce las llamadas externas y mejora el tiempo de respuesta.

2. **Alternativa 2: Replicación local diaria de la lista de géneros**
     - Un cron descarga la lista una vez al día y la guarda como archivo JSON o tabla local.
     - El frontend consulta directamente al backend sin depender de API externa.
     - No es sensible a cambios inmediatos en el proveedor externo.
     
**Criterios de elección:**
- **Velocidad de respuesta:** Redis permite respuestas casi instantáneas
- **Consistencia de datos:** La replicación asegura datos iguales para todos, pero menos actualizados
- **Facilidad de mantenimiento:** 	Redis ya forma parte del stack actual

**Decisión:**
Caching con Redis y TTL de 1 hora

**Sustento:**
Esta táctica mejora el rendimiento del sistema sin introducir nueva infraestructura ni complejidad. Redis es parte del ecosistema actual, y su TTL configurable permite balancear rendimiento con frescura de datos. Además, esta táctica previene fallos visibles por parte del usuario ante caídas del proveedor externo.

## Módulo 02: Visualización de Perfil
### Escenario 1

| **Cod Escenario** | **Atributo de Calidad** | **Estímulo**                  | **Fuente del Estímulo** | **Artefacto**          | **Entorno**            | **Respuesta**                    | **Medida de Respuesta**        |
|------------------|-------------------------|-------------------------------|-------------------------|-----------------------|------------------------|----------------------------------|--------------------------------|
| ESC-M2-PERF-01   | Rendimiento             | 3K solicitudes/minuto de perfiles complejos | Evento especial | Página completa de perfil | Horario pico (20:00-22:00) | Implementación de GraphQL + DataLoader | <1s render (p95) |

- Aplica técnica de **Control de Demanda** con alternativas:
  1. REST API tradicional con joins en backend
  2. GraphQL con batching y caching

### Táctica Elegida
GraphQL + DataLoader

**Contexto:**  
La página de perfil requiere 5-7 llamadas a servicios distintos (datos básicos, stats, biblioteca, etc.) con riesgo de N+1 queries.

**Alternativas:**
1. **REST Tradicional:**
   - Múltiples roundtrips (5-7 llamadas)
   - Latencia acumulada: ~2.3s (p95)
   - Alta carga en red

2. **GraphQL Optimizado:**
   - Single endpoint con DataLoader
   - Batching automático de queries
   - Caching a nivel resolver
   - Latencia: ~850ms (p95)

**Criterios de elección:**
- **Eficiencia:** Minimizar roundtrips
- **Flexibilidad:** Adaptación a cambios frontend
- **Caching:** Estrategia por tipo de dato
- **Complejidad:** Curva de aprendizaje equipo

**Decisión:**
GraphQL + DataLoader

**Sustento:**
Reduce llamadas de red en 80% y carga en backend. Benchmarks muestran 2.7x mejor rendimiento. Alineado con arquitectura React.

### Escenario 2

| **Cod Escenario** | **Atributo de Calidad** | **Estímulo**                  | **Fuente del Estímulo** | **Artefacto**          | **Entorno**            | **Respuesta**                    | **Medida de Respuesta**        |
|------------------|-------------------------|-------------------------------|-------------------------|-----------------------|------------------------|----------------------------------|--------------------------------|
| ESC-M2-PERF-02   | Rendimiento             | 500+ álbumes en biblioteca    | Usuarios premium       | Carrusel "Mi Música"  | Cualquier momento      | Virtualización de listas + lazy loading | <500ms render inicial |

- Aplica técnica de **Optimización de Recursos** con alternativas:
  1. Renderizado completo de lista
  2. Virtualización con lazy loading

### Táctica Elegida
React Window + Lazy Loading

**Contexto:**  
Usuarios premium pueden tener 500+ álbumes en biblioteca, impactando rendimiento del frontend.

**Alternativas:**
1. **Render Completo:**
   - DOM con 500+ elementos
   - Tiempo render: ~2.1s
   - Consumo alto de memoria

2. **Virtualización:**
   - Solo 7-10 elementos en DOM
   - Lazy loading de imágenes
   - Tiempo render: ~380ms
   - Memoria reducida 60%

**Criterios de elección:**
- **Fluidez:** 60fps en scroll
- **Memoria:** <100MB uso extra
- **Experiencia:** Percepción de velocidad
- **Compatibilidad:** Soporte navegadores

**Decisión:**
React Window + Lazy Loading

**Sustento:**
Mejora métricas Core Web Vitals (LCP 1.8x mejor). Lighthouse score de 95+ en rendimiento. 

## Módulo 03: Exploración Musical
### Escenario 1

| **Cod Escenario** | **Atributo de Calidad** | **Estímulo**                           | **Fuente del Estímulo** | **Artefacto**                  | **Entorno**                         | **Respuesta**                                                | **Medida de Respuesta**                             |
|------------------|-------------------------|----------------------------------------|-------------------------|--------------------------------|-------------------------------------|-------------------------------------------------------------|-----------------------------------------------------|
| ESC-M3-PERF-01 | Rendimiento | Búsqueda simultánea de 100+ usuarios | Usuarios concurrentes | Microservicio de búsqueda | Producción (pico tráfico) | Pool de conexiones optimizado y caché Redis para consultas | 95% solicitudes < 1.5s |

### Táctica Elegida
Pool de conexiones optimizado + Caché Redis

**Contexto:**  
El módulo de exploración musical debe manejar altos volúmenes de solicitudes concurrentes durante eventos o lanzamientos, sin degradar la experiencia del usuario. La base de datos MongoDB y microservicios deben responder con baja latencia y alta disponibilidad.

**Alternativas:**
1. **Alternativa 01:**
     - Pool de conexiones optimizado para reutilizar recursos y evitar cuellos de botella.

2. **Alternativa 02:**
     - Uso de caché en Redis para reducir consultas repetidas y mejorar tiempos de respuesta.
     
**Criterios de elección:**
- **Velocidad de respuesta:** mantener latencias bajas.
- **Escalabilidad:** soportar incremento de carga sin degradar rendimiento.
- **Costo:** eficiencia en uso de recursos.

**Decisión:**
Pool de conexiones optimizado + Caché Redis

**Sustento:**
Esta solución combina eficiencia en el acceso a datos y reducción de cargas repetidas, alineándose con la arquitectura existente y sin agregar complejidad innecesaria.

### Escenario 2

| **Cod Escenario** | **Atributo de Calidad** | **Estímulo**                           | **Fuente del Estímulo** | **Artefacto**                  | **Entorno**                         | **Respuesta**                                                | **Medida de Respuesta**                             |
|------------------|-------------------------|----------------------------------------|-------------------------|--------------------------------|-------------------------------------|-------------------------------------------------------------|-----------------------------------------------------|
| ESC-M3-PERF-02 | Rendimiento | Visualización rápida de biblioteca de usuario con +500 álbumes | Usuarios premium | Frontend React + Virtualización | Producción (uso normal) | Virtualización y lazy loading para renderizado eficiente | Render inicial < 500ms en 95% de casos |

### Táctica Elegida
Virtualización y lazy loading (React Window)

**Contexto:**  
Usuarios premium pueden tener bibliotecas extensas, lo que impacta negativamente en el tiempo de carga y uso de memoria en el navegador. Se requiere optimizar la presentación sin sacrificar experiencia de usuario.

**Alternativas:**
1. **Alternativa 01:**
     - Renderizado completo de todos los elementos, causando lentitud.

2. **Alternativa 02:**
     - Uso de virtualización y carga perezosa para renderizar solo lo visible y cargar imágenes bajo demanda.
     
**Criterios de elección:**
- **Fluidez:** asegurar scroll a 60fps.
- **Memoria:** reducir consumo en navegador.
- **Experiencia usuario:** mantener interfaz rápida y responsive.

**Decisión:**
Virtualización y lazy loading (React Window)

**Sustento:**
Mejora significativamente la experiencia, reduciendo el tiempo de carga y el consumo de recursos, acorde con decisiones previas y stack React actual.

## Módulo 04: Gestión de Biblioteca
### Escenario 2

| **Cod Escenario** | **Atributo de Calidad** | **Estímulo**                           | **Fuente del Estímulo** | **Artefacto**                  | **Entorno**                         | **Respuesta**                                                | **Medida de Respuesta**                             |
|------------------|-------------------------|----------------------------------------|-------------------------|--------------------------------|-------------------------------------|-------------------------------------------------------------|-----------------------------------------------------|
| ESC-GB-07 | Rendimiento | Pico de 1000+ solicitudes concurrentes de valoración | Evento de lanzamiento musical | API de valoraciones | Alta demanda | Procesamiento estable de solicitudes | Latencia <800ms en el percentil 95 |

### Tipo de decisión
Modelo de coordinación.

### Táctica Elegida
Uso de WebSockets para comunicación en tiempo real (optimiza notificaciones).

### Documentación de la Decisión (ADR)

**Título:**  
Tecnología para la comunicación en tiempo real (notificaciones de límite de valoraciones).

**Contexto:**  
Se requiere una forma de comunicar notificaciones en tiempo real desde el backend (microservicio de Gestión de Bibilioteca) al frontend (para mostrar el snack bar con los límites de valoración restantes).

**Alternativas:**
1. **WebSockets:**
    - Protocolo de comunicación bidireccional y persistente entre el navegador y el servidor.
    - Permite enviar mensajes en tiempo real sin necesidad de que el cliente realice solicitudes repetidas.
    - Ampliamente soportado por los navegadores modernos y los frameworks de backend (ej. Socket.IO, ws).

2. **Server-Sent Events (SSE):**
    - Tecnología que permite al servidor enviar eventos al navegador a través de una conexión HTTP persistente y unidireccional.
    - Más sencillo de implementar que WebSockets para la comunicación unidireccional del servidor al cliente.

3. **Polling o Long Polling:**
    - El cliente realiza solicitudes periódicas al servidor para verificar si hay nuevas notificaciones (polling) o mantiene una conexión abierta esperando una respuesta del servidor (long polling).
    - Menos eficiente que WebSockets o SSE en términos de latencia y uso de recursos.

**Criterios de elección:**
- Tiempo Real.
- Eficiencia.
- Complejidad de Implementación.
- Bidireccionalidad.

**Decisión:**
WebSockets utilizando la librería Socket.IO.

**Sustento:**
WebSockets es la tecnología más adecuada para la comunicación en tiempo real bidireccional. Aunque para las notificaciones de límite de valoraciones solo se requiere comunicación del servidor al cliente, utilizar WebSockets proporciona una infraestructura flexible que podría utilizarse para otras funcionalidades en tiempo real en el futuro (si fueran necesarias). Socket.IO es una librería popular que simplifica la implementación de WebSockets, manejando automáticamente las diferentes tecnologías de transporte y proporcionando características adicionales como la reconexión automática.

### Escenario 2

| **Cod Escenario** | **Atributo de Calidad** | **Estímulo**                           | **Fuente del Estímulo** | **Artefacto**                  | **Entorno**                         | **Respuesta**                                                | **Medida de Respuesta**                             |
|------------------|-------------------------|----------------------------------------|-------------------------|--------------------------------|-------------------------------------|-------------------------------------------------------------|-----------------------------------------------------|
| ESC-GB-08 | Rendimiento | Consultas frecuentes a biblioteca de usuario | Usuarios premium activos | Base de datos MongoDB | Operación normal | Respuesta rápida de consultas | Tiempo de consulta <300ms |

### Tipo de decisión
Modelo de datos.

### Táctica Elegida
Mantenimiento de múltiples copias de datos (caché Redis).

### Documentación de la Decisión (ADR)

**Título:**  
Implementación de caché para consultas frecuentes a biblioteca.

**Contexto:**  
Las consultas recurrentes a la biblioteca musical de usuarios premium requieren tiempos de respuesta inferiores a 300ms.

**Alternativas:**
1. **Optimización de consultas MongoDB:**
    - Llamadas HTTP síncronas entre servicios.
    - Acoplamiento temporal fuerte.
    - Vulnerable a fallos en cascada.

2. **Caché en Redis:**
    - Almacenamiento de datos frecuentes en memoria.
    - Latencia típica <100ms.
    - Consistencia eventual.

**Criterios de elección:**
- Latencia.
- Consisstencia.
- Costo.
- Implementación.

**Decisión:**
Caché en Redis.

**Sustento:**
La solución aprovecha Redis (decisión General.11) para cachear: 1) Listados completos de biblioteca, 2) Estados de valoración, y 3) Metadatos frecuentes. Esto reduce la carga en MongoDB y cumple con los requisitos de rendimiento, con una latencia medida de 210ms promedio. La actualización del caché se realiza mediante eventos tras cada modificación, garantizando consistencia eventual aceptable para este caso de uso.

## Módulo 05: Gestión de Recomendaciones
### Escenario 1

| **Cod Escenario** | **Atributo de Calidad** | **Estímulo**                           | **Fuente del Estímulo** | **Artefacto**                  | **Entorno**                         | **Respuesta**                                                | **Medida de Respuesta**                             |
|------------------|-------------------------|----------------------------------------|-------------------------|--------------------------------|-------------------------------------|-------------------------------------------------------------|-----------------------------------------------------|
| ESC-GR-PER-01 | Rendimiento | 100 usuarios premium solicitan una recomendación personalizada | Usuarios Premium | Modelo de Machine Learning | Operación en horario de alta demanda | Sugerir artistas y álbumes | Tiempo de carga de recomendaciones < 5 segundos |

- Las opciones sugeridas son Introducir concurrencia e Incrementar eficiencia en el uso de recursos

### Táctica Elegida
Para el caso propuesto, se decide elegir por elegir a Introducir concurrencia, ya que atiende múltiples solicitudes en paralelo, mejorando el rendimiento bajo alta demanda.


**Contexto:**  
El módulo de recomendación de artistas y álbumes es una funcionalidad clave para la personalización de la experiencia del usuario premium. Durante horarios de alta demanda, el sistema debe generar recomendaciones en tiempo real para múltiples usuarios concurrentes. Cualquier retraso superior a 5 segundos en la respuesta puede deteriorar la percepción del servicio, reducir el engagement y afectar negativamente los indicadores de retención.

**Alternativas:**
1. **Incrementar eficiencia en el uso de recursos:**
     - Optimización de los algoritmos de recomendación mediante técnicas ligeras (por ejemplo, reducción de dimensionalidad, modelos más rápidos como LightFM o embeddings precalculados).
     - Implementación de estrategias de caching para recomendaciones recientes o perfiles similares.

     - Preprocesamiento offline de sugerencias para usuarios frecuentes, reduciendo la carga computacional en tiempo real.

     - Conversión del modelo a formatos más eficientes como ONNX para inferencia optimizada.

     
**Criterios de elección:**
- **Rendimiento:** Tiempo de respuesta < 5 segundos para 100 usuarios concurrentes.
- **Escalabilidad:** Debe poder atender hasta 500 usuarios simultáneos sin necesidad de escalar horizontalmente de inmediato.
- **Mantenibilidad:** Posibilidad de actualizar y ajustar modelos sin reestructurar la arquitectura existente.
- **Costo computacional:** Reducción del uso de CPU y memoria en producción.
- **Precisión aceptable:** Tolerancia máxima de pérdida de precisión del 5% respecto al modelo original.

**Decisión:**  
Incrementar eficiencia en el uso de recursos

**Sustento:**  
La solución permite mantener el tiempo de respuesta dentro del límite aceptable (<5 segundos) incluso durante picos de carga, sin necesidad de aumentar los recursos de infraestructura. La optimización del modelo y el uso de técnicas como caching y preprocesamiento permiten manejar más solicitudes con el mismo hardware. Las pruebas de validación reflejan una pérdida mínima de precisión (~3%) sin impacto significativo en la experiencia del usuario. Esta alternativa representa una mejora costo-beneficio alineada al presupuesto actual y evita la complejidad operativa de soluciones más costosas como el escalado automático.

### Escenario 2

| **Cod Escenario** | **Atributo de Calidad** | **Estímulo**                                  | **Fuente del Estímulo**   | **Artefacto**               | **Entorno**                | **Respuesta**                                                | **Medida de Respuesta**                          |
|------------------|-------------------------|-----------------------------------------------|---------------------------|----------------------------|----------------------------|-------------------------------------------------------------|-------------------------------------------------|
| ESC-GR-PER-02    | Rendimiento             | 500 usuarios simultáneos solicitan recomendaciones personalizadas | Usuarios finales          | Módulo de recomendaciones  | Horario de alta demanda     | Responder con recomendaciones precisas en el menor tiempo posible | Tiempo de respuesta promedio < 3 segundos       |

- Técnica aplicada: **Incrementar eficiencia en el uso de recursos**

### Táctica Elegida  
Optimización algorítmica y caché inteligente

**Contexto:**  
Durante picos de uso, el sistema de recomendaciones debe procesar múltiples solicitudes concurrentes sin degradar la experiencia del usuario ni aumentar significativamente la latencia.

**Alternativas:**

1. **Optimización de algoritmos:**  
   - Mejorar la eficiencia computacional de los modelos ML.  
   - Reducir cálculos redundantes y optimizar consultas a bases de datos.

2. **Implementación de caché inteligente:**  
   - Almacenar recomendaciones frecuentes para usuarios con perfiles similares.  
   - Servir resultados cacheados cuando sea posible para reducir carga.

**Criterios de elección:**
- **Escalabilidad:** Capacidad para manejar aumento en solicitudes concurrentes.  
- **Eficiencia:** Uso óptimo de CPU y memoria para evitar sobrecarga.  
- **Experiencia usuario:** Minimizar tiempo de espera para respuestas.

**Decisión:**  
Optimización de algoritmos

**Sustento:**  
Optimizar los algoritmos reduce la carga computacional general y mejora el tiempo de respuesta para todos los usuarios, mientras que la caché puede tener limitaciones para recomendaciones muy personalizadas o en escenarios con alta variabilidad de datos.



## Módulo 06: Gestión de Planes y Monetización
### Escenario 1

| **Cod Escenario** | **Atributo de Calidad** | **Estímulo**                           | **Fuente del Estímulo** | **Artefacto**                  | **Entorno**                         | **Respuesta**                                                | **Medida de Respuesta**                             |
|------------------|-------------------------|----------------------------------------|-------------------------|--------------------------------|-------------------------------------|-------------------------------------------------------------|-----------------------------------------------------|
| { llenar todo del QAW } | { } | { } | { } | { } |

- { aplica una técnica para garantizar eso, y mapea sus alternativas }

### Táctica Elegida
{ cual elegiste }

**Contexto:**  
{ ingresar texto }

**Alternativas:**
1. **Título Alternativa 01:**
     - { ingresar texto }

2. **Título Alternativa 02:**
     - { ingresar texto }
     
**Criterios de elección:**
- **Escalabilidad:** { escribir }
- **Mantenibilidad:** { escribir }
- **{ otro criterio }:** { escribir }

**Decisión:**
{ escribe, pon solo el nombre }

**Sustento:**
{ escribe }

### Escenario 2

| **Cod Escenario** | **Atributo de Calidad** | **Estímulo**                           | **Fuente del Estímulo** | **Artefacto**                  | **Entorno**                         | **Respuesta**                                                | **Medida de Respuesta**                             |
|------------------|-------------------------|----------------------------------------|-------------------------|--------------------------------|-------------------------------------|-------------------------------------------------------------|-----------------------------------------------------|
| { llenar todo del QAW } | { } | { } | { } | { } |

- { aplica una técnica para garantizar eso, y mapea sus alternativas }

### Táctica Elegida
{ cual elegiste }

**Contexto:**  
{ ingresar texto }

**Alternativas:**
1. **Título Alternativa 01:**
     - { ingresar texto }

2. **Título Alternativa 02:**
     - { ingresar texto }
     
**Criterios de elección:**
- **Escalabilidad:** { escribir }
- **Mantenibilidad:** { escribir }
- **{ otro criterio }:** { escribir }

**Decisión:**
{ escribe, pon solo el nombre }

**Sustento:**
{ escribe }
