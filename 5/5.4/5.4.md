# 5.4. Rendimiento

## Módulo 01: Gestión de Usuarios
### Escenario 1

| **Cod Escenario** | **Atributo de Calidad** | **Estímulo**                           | **Fuente del Estímulo** | **Artefacto**                  | **Entorno**                         | **Respuesta**                                                | **Medida de Respuesta**                             |
|------------------|-------------------------|----------------------------------------|-------------------------|--------------------------------|-------------------------------------|-------------------------------------------------------------|-----------------------------------------------------|
| ESC-GU-07 | Eficiencia | 15 registros simultáneos | Sistema | Node.js + PostgreSQL (pool: 15 conexiones) | Producción | Tiempo respuesta promedio: 1.2s | 95% requests <1.5s (k6 con 100 VUs) |

- Elección entre Pool de conexiones optimizado en Sequelize y Implementación de cola asincrónica con BullMQ

### Táctica Elegida
Pool de conexiones optimizado en Sequelize

**Contexto:**  
El registro de usuarios es uno de los puntos de mayor tráfico en el Módulo 1. En campañas de lanzamiento, la plataforma puede recibir múltiples formularios al mismo tiempo. Esto puede provocar cuellos de botella en la conexión a la base de datos. El backend utiliza Node.js, Sequelize y PostgreSQL, y está desplegado en contenedores escalables por Kubernetes.

**Alternativas:**
1. **Alternativa 1: Pool de conexiones optimizado en Sequelize**
     - Configurar max, min y idle apropiadamente en el pool.
     - Permite reutilizar conexiones a la base de datos.
     - Escalable horizontalmente con réplicas backend.

2. **Alternativa 2: Implementación de cola asincrónica con BullMQ**
     - Las peticiones de registro son encoladas.
     - Un worker procesa los registros uno por uno.
     - Aumenta la tolerancia a picos altos de tráfico.
     
**Criterios de elección:**
- **Velocidad de respuesta:** El pool responde en tiempo real; la cola introduce latencia controlada
- **Escalabilidad horizontal:** Pool más simple de escalar; la cola requiere workers dedicados
- **Tamaño del tráfico esperado:** El pool cubre la demanda media; BullMQ es mejor para grandes picos

**Decisión:**
Pool de conexiones optimizado en Sequelize

**Sustento:**
La demanda esperada (15 usuarios simultáneos) se maneja eficientemente con un pool correctamente configurado. Sequelize permite controlar este comportamiento fácilmente, y se alinea con las decisiones existentes del stack (sin introducir complejidad adicional como colas o workers). Además, Kubernetes facilita el escalamiento si se requiere mayor capacidad en el futuro.

### Escenario 2

| **Cod Escenario** | **Atributo de Calidad** | **Estímulo**                           | **Fuente del Estímulo** | **Artefacto**                  | **Entorno**                         | **Respuesta**                                                | **Medida de Respuesta**                             |
|------------------|-------------------------|----------------------------------------|-------------------------|--------------------------------|-------------------------------------|-------------------------------------------------------------|-----------------------------------------------------|
| ESC-GU-08 | Eficiencia | Fallo servicio géneros musicales | API externa | Redis Cache (TTL 1h) | Producción | Respuesta con datos cacheados + timestamp | 70% reducción llamadas fallidas (Prometheus) |

- Elección entre Caching con Redis y TTL de 1 hora y Replicación local diaria de la lista de géneros

### Táctica Elegida
Caching con Redis y TTL de 1 hora

**Contexto:**  
Durante el registro de usuarios o configuración inicial del perfil, se solicita una lista de géneros musicales (usada también en recomendaciones y búsquedas). Esta lista proviene de una API externa, por lo que puede fallar o ser lenta. Para mejorar el rendimiento y asegurar una experiencia estable, se requiere una táctica de caching robusta y sencilla.

**Alternativas:**
1. **Alternativa 1: Caching con Redis y TTL de 1 hora**
     - Cada vez que se solicitan géneros, se consulta Redis primero.
     - Si no existe en caché, se obtiene desde la API externa y se guarda.
     - Reduce las llamadas externas y mejora el tiempo de respuesta.

2. **Alternativa 2: Replicación local diaria de la lista de géneros**
     - Un cron descarga la lista una vez al día y la guarda como archivo JSON o tabla local.
     - El frontend consulta directamente al backend sin depender de API externa.
     - No es sensible a cambios inmediatos en el proveedor externo.
     
**Criterios de elección:**
- **Velocidad de respuesta:** Redis permite respuestas casi instantáneas
- **Consistencia de datos:** La replicación asegura datos iguales para todos, pero menos actualizados
- **Facilidad de mantenimiento:** 	Redis ya forma parte del stack actual

**Decisión:**
Caching con Redis y TTL de 1 hora

**Sustento:**
Esta táctica mejora el rendimiento del sistema sin introducir nueva infraestructura ni complejidad. Redis es parte del ecosistema actual, y su TTL configurable permite balancear rendimiento con frescura de datos. Además, esta táctica previene fallos visibles por parte del usuario ante caídas del proveedor externo.

## Módulo 02: Visualización de Perfil
### Escenario 1

| **Cod Escenario** | **Atributo de Calidad** | **Estímulo**                  | **Fuente del Estímulo** | **Artefacto**          | **Entorno**            | **Respuesta**                    | **Medida de Respuesta**        |
|------------------|-------------------------|-------------------------------|-------------------------|-----------------------|------------------------|----------------------------------|--------------------------------|
| ESC-VP-07   | Rendimiento             | 3K solicitudes/minuto de perfiles complejos | Evento especial | Página completa de perfil | Horario pico (20:00-22:00) | Implementación de GraphQL + DataLoader | <1s render (p95) |

- Aplica técnica de **Control de Demanda** con alternativas:
  1. REST API tradicional con joins en backend
  2. GraphQL con batching y caching

### Táctica Elegida
GraphQL + DataLoader

**Contexto:**  
La página de perfil requiere 5-7 llamadas a servicios distintos (datos básicos, stats, biblioteca, etc.) con riesgo de N+1 queries.

**Alternativas:**
1. **REST Tradicional:**
   - Múltiples roundtrips (5-7 llamadas)
   - Latencia acumulada: ~2.3s (p95)
   - Alta carga en red

2. **GraphQL Optimizado:**
   - Single endpoint con DataLoader
   - Batching automático de queries
   - Caching a nivel resolver
   - Latencia: ~850ms (p95)

**Criterios de elección:**
- **Eficiencia:** Minimizar roundtrips
- **Flexibilidad:** Adaptación a cambios frontend
- **Caching:** Estrategia por tipo de dato
- **Complejidad:** Curva de aprendizaje equipo

**Decisión:**
GraphQL + DataLoader

**Sustento:**
Reduce llamadas de red en 80% y carga en backend. Benchmarks muestran 2.7x mejor rendimiento. Alineado con arquitectura React.

### Escenario 2

| **Cod Escenario** | **Atributo de Calidad** | **Estímulo**                  | **Fuente del Estímulo** | **Artefacto**          | **Entorno**            | **Respuesta**                    | **Medida de Respuesta**        |
|------------------|-------------------------|-------------------------------|-------------------------|-----------------------|------------------------|----------------------------------|--------------------------------|
| ESC-VP-08   | Rendimiento             | 500+ álbumes en biblioteca    | Usuarios premium       | Carrusel "Mi Música"  | Cualquier momento      | Virtualización de listas + lazy loading | <500ms render inicial |

- Aplica técnica de **Optimización de Recursos** con alternativas:
  1. Renderizado completo de lista
  2. Virtualización con lazy loading

### Táctica Elegida
React Window + Lazy Loading

**Contexto:**  
Usuarios premium pueden tener 500+ álbumes en biblioteca, impactando rendimiento del frontend.

**Alternativas:**
1. **Render Completo:**
   - DOM con 500+ elementos
   - Tiempo render: ~2.1s
   - Consumo alto de memoria

2. **Virtualización:**
   - Solo 7-10 elementos en DOM
   - Lazy loading de imágenes
   - Tiempo render: ~380ms
   - Memoria reducida 60%

**Criterios de elección:**
- **Fluidez:** 60fps en scroll
- **Memoria:** <100MB uso extra
- **Experiencia:** Percepción de velocidad
- **Compatibilidad:** Soporte navegadores

**Decisión:**
React Window + Lazy Loading

**Sustento:**
Mejora métricas Core Web Vitals (LCP 1.8x mejor). Lighthouse score de 95+ en rendimiento. 

## Módulo 03: Exploración Musical
### Escenario 1

| **Cod Escenario** | **Atributo de Calidad** | **Estímulo**                           | **Fuente del Estímulo** | **Artefacto**                  | **Entorno**                         | **Respuesta**                                                | **Medida de Respuesta**                             |
|------------------|-------------------------|----------------------------------------|-------------------------|--------------------------------|-------------------------------------|-------------------------------------------------------------|-----------------------------------------------------|
| ESC-EM-07 | Rendimiento | Búsqueda simultánea de 100+ usuarios | Usuarios concurrentes | Microservicio de búsqueda | Producción (pico tráfico) | Pool de conexiones optimizado y caché Redis para consultas | 95% solicitudes < 1.5s |

### Táctica Elegida
Pool de conexiones optimizado + Caché Redis (táctica ya tomada en la decisión arquitectónica del Módulo 01 — Escenario 01)

### Escenario 2

| **Cod Escenario** | **Atributo de Calidad** | **Estímulo**                           | **Fuente del Estímulo** | **Artefacto**                  | **Entorno**                         | **Respuesta**                                                | **Medida de Respuesta**                             |
|------------------|-------------------------|----------------------------------------|-------------------------|--------------------------------|-------------------------------------|-------------------------------------------------------------|-----------------------------------------------------|
| ESC-EM-08 | Rendimiento | Visualización rápida de biblioteca de usuario con +500 álbumes | Usuarios premium | Frontend React + Virtualización | Producción (uso normal) | Virtualización y lazy loading para renderizado eficiente | Render inicial < 500ms en 95% de casos |

### Táctica Elegida
Virtualización y lazy loading (React Window) (táctica ya tomada en la decisión arquitectónica del Módulo 02 — Escenario 02)

## Módulo 04: Gestión de Biblioteca
### Escenario 2

| **Cod Escenario** | **Atributo de Calidad** | **Estímulo**                           | **Fuente del Estímulo** | **Artefacto**                  | **Entorno**                         | **Respuesta**                                                | **Medida de Respuesta**                             |
|------------------|-------------------------|----------------------------------------|-------------------------|--------------------------------|-------------------------------------|-------------------------------------------------------------|-----------------------------------------------------|
| ESC-GB-07 | Rendimiento | Pico de 1000+ solicitudes concurrentes de valoración | Evento de lanzamiento musical | API de valoraciones | Alta demanda | Procesamiento estable de solicitudes | Latencia <800ms en el percentil 95 |

### Tipo de decisión
Modelo de coordinación.

### Táctica Elegida
Uso de WebSockets para comunicación en tiempo real (optimiza notificaciones).

### Documentación de la Decisión (ADR)

**Título:**  
Tecnología para la comunicación en tiempo real (notificaciones de límite de valoraciones).

**Contexto:**  
Se requiere una forma de comunicar notificaciones en tiempo real desde el backend (microservicio de Gestión de Bibilioteca) al frontend (para mostrar el snack bar con los límites de valoración restantes).

**Alternativas:**
1. **WebSockets:**
    - Protocolo de comunicación bidireccional y persistente entre el navegador y el servidor.
    - Permite enviar mensajes en tiempo real sin necesidad de que el cliente realice solicitudes repetidas.
    - Ampliamente soportado por los navegadores modernos y los frameworks de backend (ej. Socket.IO, ws).

2. **Server-Sent Events (SSE):**
    - Tecnología que permite al servidor enviar eventos al navegador a través de una conexión HTTP persistente y unidireccional.
    - Más sencillo de implementar que WebSockets para la comunicación unidireccional del servidor al cliente.

3. **Polling o Long Polling:**
    - El cliente realiza solicitudes periódicas al servidor para verificar si hay nuevas notificaciones (polling) o mantiene una conexión abierta esperando una respuesta del servidor (long polling).
    - Menos eficiente que WebSockets o SSE en términos de latencia y uso de recursos.

**Criterios de elección:**
- Tiempo Real.
- Eficiencia.
- Complejidad de Implementación.
- Bidireccionalidad.

**Decisión:**
WebSockets utilizando la librería Socket.IO.

**Sustento:**
WebSockets es la tecnología más adecuada para la comunicación en tiempo real bidireccional. Aunque para las notificaciones de límite de valoraciones solo se requiere comunicación del servidor al cliente, utilizar WebSockets proporciona una infraestructura flexible que podría utilizarse para otras funcionalidades en tiempo real en el futuro (si fueran necesarias). Socket.IO es una librería popular que simplifica la implementación de WebSockets, manejando automáticamente las diferentes tecnologías de transporte y proporcionando características adicionales como la reconexión automática.

### Escenario 2

| **Cod Escenario** | **Atributo de Calidad** | **Estímulo**                           | **Fuente del Estímulo** | **Artefacto**                  | **Entorno**                         | **Respuesta**                                                | **Medida de Respuesta**                             |
|------------------|-------------------------|----------------------------------------|-------------------------|--------------------------------|-------------------------------------|-------------------------------------------------------------|-----------------------------------------------------|
| ESC-EM-08 | Rendimiento | Consultas frecuentes a biblioteca de usuario | Usuarios premium activos | Base de datos MongoDB | Operación normal | Respuesta rápida de consultas | Tiempo de consulta <300ms |

### Tipo de decisión
Modelo de datos.

### Táctica Elegida
Mantenimiento de múltiples copias de datos (caché Redis) (táctica ya tomada en la decisión arquitectónica del Módulo 01 — Escenario 02).

## Módulo 05: Gestión de Recomendaciones
### Escenario 1

| **Cod Escenario** | **Atributo de Calidad** | **Estímulo**                           | **Fuente del Estímulo** | **Artefacto**                  | **Entorno**                         | **Respuesta**                                                | **Medida de Respuesta**                             |
|------------------|-------------------------|----------------------------------------|-------------------------|--------------------------------|-------------------------------------|-------------------------------------------------------------|-----------------------------------------------------|
| ESC-GR-07 | Rendimiento | 100 usuarios premium solicitan una recomendación personalizada | Usuarios Premium | Modelo de Machine Learning | Operación en horario de alta demanda | Sugerir artistas y álbumes | Tiempo de carga de recomendaciones < 5 segundos |

- Las opciones sugeridas son Introducir concurrencia e Incrementar eficiencia en el uso de recursos

### Táctica Elegida
Para el caso propuesto, se decide elegir por elegir a Introducir concurrencia, ya que atiende múltiples solicitudes en paralelo, mejorando el rendimiento bajo alta demanda.


**Contexto:**  
El módulo de recomendación de artistas y álbumes es una funcionalidad clave para la personalización de la experiencia del usuario premium. Durante horarios de alta demanda, el sistema debe generar recomendaciones en tiempo real para múltiples usuarios concurrentes. Cualquier retraso superior a 5 segundos en la respuesta puede deteriorar la percepción del servicio, reducir el engagement y afectar negativamente los indicadores de retención.

**Alternativas:**
1. **Incrementar eficiencia en el uso de recursos:**
     - Optimización de los algoritmos de recomendación mediante técnicas ligeras (por ejemplo, reducción de dimensionalidad, modelos más rápidos como LightFM o embeddings precalculados).
     - Implementación de estrategias de caching para recomendaciones recientes o perfiles similares.

     - Preprocesamiento offline de sugerencias para usuarios frecuentes, reduciendo la carga computacional en tiempo real.

     - Conversión del modelo a formatos más eficientes como ONNX para inferencia optimizada.

     
**Criterios de elección:**
- **Rendimiento:** Tiempo de respuesta < 5 segundos para 100 usuarios concurrentes.
- **Escalabilidad:** Debe poder atender hasta 500 usuarios simultáneos sin necesidad de escalar horizontalmente de inmediato.
- **Mantenibilidad:** Posibilidad de actualizar y ajustar modelos sin reestructurar la arquitectura existente.
- **Costo computacional:** Reducción del uso de CPU y memoria en producción.
- **Precisión aceptable:** Tolerancia máxima de pérdida de precisión del 5% respecto al modelo original.

**Decisión:**  
Incrementar eficiencia en el uso de recursos

**Sustento:**  
La solución permite mantener el tiempo de respuesta dentro del límite aceptable (<5 segundos) incluso durante picos de carga, sin necesidad de aumentar los recursos de infraestructura. La optimización del modelo y el uso de técnicas como caching y preprocesamiento permiten manejar más solicitudes con el mismo hardware. Las pruebas de validación reflejan una pérdida mínima de precisión (~3%) sin impacto significativo en la experiencia del usuario. Esta alternativa representa una mejora costo-beneficio alineada al presupuesto actual y evita la complejidad operativa de soluciones más costosas como el escalado automático.

### Escenario 2

| **Cod Escenario** | **Atributo de Calidad** | **Estímulo**                                  | **Fuente del Estímulo**   | **Artefacto**               | **Entorno**                | **Respuesta**                                                | **Medida de Respuesta**                          |
|------------------|-------------------------|-----------------------------------------------|---------------------------|----------------------------|----------------------------|-------------------------------------------------------------|-------------------------------------------------|
| ESC-GR-08    | Rendimiento             | 500 usuarios simultáneos solicitan recomendaciones personalizadas | Usuarios finales          | Módulo de recomendaciones  | Horario de alta demanda     | Responder con recomendaciones precisas en el menor tiempo posible | Tiempo de respuesta promedio < 3 segundos       |

- Técnica aplicada: **Incrementar eficiencia en el uso de recursos**

### Táctica Elegida  
Optimización algorítmica y caché inteligente

**Contexto:**  
Durante picos de uso, el sistema de recomendaciones debe procesar múltiples solicitudes concurrentes sin degradar la experiencia del usuario ni aumentar significativamente la latencia.

**Alternativas:**

1. **Optimización de algoritmos:**  
   - Mejorar la eficiencia computacional de los modelos ML.  
   - Reducir cálculos redundantes y optimizar consultas a bases de datos.

2. **Implementación de caché inteligente:**  
   - Almacenar recomendaciones frecuentes para usuarios con perfiles similares.  
   - Servir resultados cacheados cuando sea posible para reducir carga.

**Criterios de elección:**
- **Escalabilidad:** Capacidad para manejar aumento en solicitudes concurrentes.  
- **Eficiencia:** Uso óptimo de CPU y memoria para evitar sobrecarga.  
- **Experiencia usuario:** Minimizar tiempo de espera para respuestas.

**Decisión:**  
Optimización de algoritmos

**Sustento:**  
Optimizar los algoritmos reduce la carga computacional general y mejora el tiempo de respuesta para todos los usuarios, mientras que la caché puede tener limitaciones para recomendaciones muy personalizadas o en escenarios con alta variabilidad de datos.



## Módulo 06: Gestión de Planes y Monetización

### **Escenario 1**
| **Cod Escenario** | **Atributo de Calidad** | **Estímulo** | **Fuente del Estímulo** | **Artefacto** | **Entorno** | **Respuesta** | **Medida de Respuesta** |
|------------------|-------------------------|----------------------------------------|-------------------------|--------------------------------|-------------------------------------|-------------------------------------------------------------|-----------------------------------------------------|
| ESC-GPM-06 | Rendimiento | Alta frecuencia de consultas de verificación de permisos premium durante horas pico | Microservicios del sistema (Biblioteca, Recomendaciones, Visualización) | Sistema de verificación de permisos y cache en Redis | Operación normal con 1000+ usuarios concurrentes | El sistema responde a las consultas de permisos sin degradación del tiempo de respuesta | Tiempo de respuesta promedio menor a 50ms, capacidad para 500 consultas/segundo |

### **Táctica Elegida**
Gestionar recursos mediante mantener múltiples copias de los datos

**Título:**  
Cache Distribuido Multi-Nivel para Verificación de Permisos

**Contexto:**  
Los microservicios de Biblioteca, Recomendaciones y Visualización consultan constantemente el estado premium de los usuarios para habilitar funcionalidades específicas. Durante horas pico, estas consultas pueden saturar la base de datos PostgreSQL y afectar el rendimiento general del sistema.

**Alternativas:**
1. **Cache Multi-Nivel con Estrategia de Invalidación Inteligente:**
- Cache L1 en memoria de cada microservicio para consultas muy frecuentes
- Cache L2 distribuido en Redis para compartir entre microservicios
- Cache L3 de respaldo en PostgreSQL con índices optimizados
- Invalidación inteligente basada en eventos de cambio de suscripción

2. **Réplicas de Lectura con Particionamiento por Tipo de Consulta:**
- Réplica de solo lectura de PostgreSQL dedicada a consultas de permisos
- Particionamiento de datos por tipo de plan y estado de suscripción
- Balanceador de carga para distribuir consultas entre réplicas
- Sincronización asíncrona con base de datos principal

**Criterios de elección:**
- **Latencia:** Las consultas de permisos deben resolverse en menos de 50ms
- **Throughput:** Debe soportar al menos 500 consultas por segundo
- **Consistencia:** Los permisos deben reflejar el estado actual de la suscripción

**Decisión:**
Cache Multi-Nivel con Estrategia de Invalidación Inteligente

**Sustento:**
Esta alternativa se alinea perfectamente con la decisión arquitectónica de modelo híbrido PostgreSQL + Redis con mapeo optimizado por uso. El cache multi-nivel aprovecha la infraestructura ya establecida y la invalidación inteligente garantiza consistencia de datos. Esta solución es más eficiente que las réplicas de lectura ya que mantiene los datos más frecuentemente consultados en memoria, reduciendo drasticamente la latencia y el overhead de red.

### **Escenario 2**
| **Cod Escenario** | **Atributo de Calidad** | **Estímulo** | **Fuente del Estímulo** | **Artefacto** | **Entorno** | **Respuesta** | **Medida de Respuesta** |
|------------------|-------------------------|----------------------------------------|-------------------------|--------------------------------|-------------------------------------|-------------------------------------------------------------|-----------------------------------------------------|
| ESC-GPM-07 | Rendimiento | Procesamiento de múltiples transacciones de pago concurrentes durante promociones especiales | Usuarios finales realizando suscripciones premium | Sistema de procesamiento de pagos con Stripe | Carga alta durante campañas promocionales | El sistema procesa todas las transacciones sin bloqueos ni timeouts | Capacidad para procesar 50 transacciones concurrentes, tiempo de respuesta menor a 3 segundos por transacción |

### **Táctica Elegida**
Gestionar recursos mediante introducir concurrencia

**Título:**  
Pool de Conexiones con Procesamiento Asíncrono de Transacciones

**Contexto:**  
Durante promociones especiales o lanzamientos de nuevas funcionalidades premium, se pueden generar picos de suscripciones que saturan el sistema de procesamiento de pagos. El procesamiento secuencial actual puede crear cuellos de botella y timeouts con la API de Stripe.

**Alternativas:**
1. **Pool de Workers Asíncronos con Cola de Transacciones:**
- Pool configurable de workers que procesan transacciones en paralelo
- Cola de transacciones en Redis con priorización por tipo de plan
- Control de concurrencia para respetar límites de rate de Stripe
- Mecanismo de backpressure para evitar sobrecarga del sistema

2. **Procesamiento Reactivo con Streams de Transacciones:**
- Implementación de streams reactivos para manejar flujo de transacciones
- Backpressure automático basado en la capacidad de procesamiento
- Paralelización automática según recursos disponibles
- Agregación de transacciones similares para optimizar llamadas a Stripe

**Criterios de elección:**
- **Escalabilidad:** Debe adaptarse automáticamente a variaciones de carga
- **Confiabilidad:** No debe perder transacciones durante picos de carga
- **Eficiencia:** Debe optimizar el uso de recursos sin desperdiciar capacidad

**Decisión:**
Pool de Workers Asíncronos con Cola de Transacciones

**Sustento:**
Esta alternativa es consistente con la decisión arquitectónica de coordinación secuencial síncrona pero introduce concurrencia controlada donde es necesario. El pool de workers permite procesar múltiples transacciones en paralelo mientras mantiene el control sobre los límites de la API de Stripe. La cola en Redis aprovecha la infraestructura existente y el control de concurrencia garantiza que no se excedan los límites de rate limiting, manteniendo la confiabilidad del sistema.