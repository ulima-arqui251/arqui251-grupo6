# 5.4. Rendimiento
- [Volver al índice](/5/5.md)

## Módulo 01: Gestión de usuarios
### Escenario 1

| **Cod Escenario** | **Atributo de Calidad** | **Estímulo**                           | **Fuente del Estímulo** | **Artefacto**                  | **Entorno**                         | **Respuesta**                                                | **Medida de Respuesta**                             |
|------------------|-------------------------|----------------------------------------|-------------------------|--------------------------------|-------------------------------------|-------------------------------------------------------------|-----------------------------------------------------|
| ESC-GU-06 | Rendimiento | 15 registros simultáneos | Sistema | Node.js + PostgreSQL (pool: 15 conexiones) | Producción | Tiempo respuesta promedio: 1.2s | 95% requests <1.5s (k6 con 100 VUs) |

- Elección entre Pool de conexiones optimizado en Sequelize y Implementación de cola asincrónica con BullMQ

### Táctica Elegida
Pool de conexiones optimizado en Sequelize.

**Contexto:**  
El registro de usuarios es uno de los puntos de mayor tráfico en el Módulo 1. En campañas de lanzamiento, la plataforma puede recibir múltiples formularios al mismo tiempo. Esto puede provocar cuellos de botella en la conexión a la base de datos. El backend utiliza Node.js, Sequelize y PostgreSQL, y está desplegado en contenedores escalables por Kubernetes.

**Alternativas:**
1. **Pool de conexiones optimizado en Sequelize:**
     - Configurar max, min y idle apropiadamente en el pool.
     - Permite reutilizar conexiones a la base de datos.
     - Escalable horizontalmente con réplicas backend.

2. **Implementación de cola asincrónica con BullMQ:**
     - Las peticiones de registro son encoladas.
     - Un worker procesa los registros uno por uno.
     - Aumenta la tolerancia a picos altos de tráfico.
     
**Criterios de elección:**
- **Velocidad de respuesta:** El pool responde en tiempo real; la cola introduce latencia controlada
- **Escalabilidad horizontal:** Pool más simple de escalar; la cola requiere workers dedicados
- **Tamaño del tráfico esperado:** El pool cubre la demanda media; BullMQ es mejor para grandes picos

**Decisión:**
Pool de conexiones optimizado en Sequelize.

**Sustento:**
La demanda esperada (15 usuarios simultáneos) se maneja eficientemente con un pool correctamente configurado. Sequelize permite controlar este comportamiento fácilmente, y se alinea con las decisiones existentes del stack (sin introducir complejidad adicional como colas o workers). Además, Kubernetes facilita el escalamiento si se requiere mayor capacidad en el futuro.

### Escenario 2

| **Cod Escenario** | **Atributo de Calidad** | **Estímulo**                           | **Fuente del Estímulo** | **Artefacto**                  | **Entorno**                         | **Respuesta**                                                | **Medida de Respuesta**                             |
|------------------|-------------------------|----------------------------------------|-------------------------|--------------------------------|-------------------------------------|-------------------------------------------------------------|-----------------------------------------------------|
| ESC-GU-07 | Rendimiento | Fallo servicio géneros musicales | API externa | Redis Cache (TTL 1h) | Producción | Respuesta con datos cacheados + timestamp | 70% reducción llamadas fallidas (Prometheus) |

- Elección entre Caching con Redis y TTL de 1 hora y Replicación local diaria de la lista de géneros

### Táctica Elegida
Caching con Redis y TTL de 1 hora.

**Contexto:**  
Durante el registro de usuarios o configuración inicial del perfil, se solicita una lista de géneros musicales (usada también en recomendaciones y búsquedas). Esta lista proviene de una API externa, por lo que puede fallar o ser lenta. Para mejorar el rendimiento y asegurar una experiencia estable, se requiere una táctica de caching robusta y sencilla.

**Alternativas:**
1. **Caching con Redis y TTL de 1 hora:**
     - Cada vez que se solicitan géneros, se consulta Redis primero.
     - Si no existe en caché, se obtiene desde la API externa y se guarda.
     - Reduce las llamadas externas y mejora el tiempo de respuesta.

2. **Replicación local diaria de la lista de géneros:**
     - Un cron descarga la lista una vez al día y la guarda como archivo JSON o tabla local.
     - El frontend consulta directamente al backend sin depender de API externa.
     - No es sensible a cambios inmediatos en el proveedor externo.
     
**Criterios de elección:**
- **Velocidad de respuesta:** Redis permite respuestas casi instantáneas
- **Consistencia de datos:** La replicación asegura datos iguales para todos, pero menos actualizados
- **Facilidad de mantenimiento:** 	Redis ya forma parte del stack actual

**Decisión:**
Caching con Redis y TTL de 1 hora.

**Sustento:**
Esta táctica mejora el rendimiento del sistema sin introducir nueva infraestructura ni complejidad. Redis es parte del ecosistema actual, y su TTL configurable permite balancear rendimiento con frescura de datos. Además, esta táctica previene fallos visibles por parte del usuario ante caídas del proveedor externo.

## Módulo 02: Visualización de perfil
#### Escenario 1

| **Cod Escenario** | **Atributo de Calidad** | **Estímulo**                             | **Fuente del Estímulo** | **Artefacto**              | **Entorno**                   | **Respuesta**                       | **Medida de Respuesta** |
|------------------|------------------------|------------------------------------------|------------------------|--------------------------|-----------------------------|------------------------------------|------------------------|
| ESC-VP-07        | Rendimiento             | 3K solicitudes/minuto de perfiles complejos | Evento especial         | Página completa de perfil | Horario pico (20:00-22:00) | Optimización de REST API backend | <1s render (p95)      |

- Aplica técnica de **Control de Demanda** con alternativas:
  1. REST API tradicional con joins en backend optimizados
  2. GraphQL con batching y caching (descartada)

#### Táctica Elegida
**REST API Tradicional Optimizada**

**Contexto:**  
La página de perfil requiere 5-7 llamadas a servicios distintos (datos básicos, stats, biblioteca, etc.).

**Alternativas:**

1. **REST Tradicional (Optimizado):**
   - Backend realiza joins internos eficientes (Sequelize includes, etc.)
   - Pool de conexiones ajustado
   - Caching parcial con Redis donde aplica
   - Latencia estimada: ~900ms (p95)

2. **GraphQL (Descartada):**
   - Incompatible con decisión general RESTful API
   - Aumenta complejidad de backend innecesariamente

**Criterios de elección:**
- **Consistencia:** Alineado con RESTful API
- **Simplicidad:** Uso de ORM optimizado (Sequelize)
- **Caching:** Redis para datos no volátiles
- **Mantenibilidad:** Sin curva adicional para GraphQL

**Decisión:**
REST API Tradicional Optimizada.

**Sustento:**
Mantiene la simplicidad de stack (REST), mejora latencia mediante pooling, joins y caché, evitando complejidad extra de GraphQL.

### Escenario 2

| **Cod Escenario** | **Atributo de Calidad** | **Estímulo**                  | **Fuente del Estímulo** | **Artefacto**          | **Entorno**            | **Respuesta**                    | **Medida de Respuesta**        |
|------------------|-------------------------|-------------------------------|-------------------------|-----------------------|------------------------|----------------------------------|--------------------------------|
| ESC-VP-08   | Rendimiento             | 500+ álbumes en biblioteca    | Usuarios premium       | Carrusel "Mi Música"  | Cualquier momento      | Virtualización de listas + lazy loading | <500ms render inicial |

- Aplica técnica de **Optimización de Recursos** con alternativas:
  1. Renderizado completo de lista
  2. Virtualización con lazy loading

### Táctica Elegida
React Window + Lazy Loading.

**Contexto:**  
Usuarios premium pueden tener 500+ álbumes en biblioteca, impactando rendimiento del frontend.

**Alternativas:**
1. **Render Completo:**
   - DOM con 500+ elementos
   - Tiempo render: ~2.1s
   - Consumo alto de memoria

2. **Virtualización con lazy loading:**
   - Solo 7-10 elementos en DOM
   - Lazy loading de imágenes
   - Tiempo render: ~380ms
   - Memoria reducida 60%

**Criterios de elección:**
- **Fluidez:** 60fps en scroll
- **Memoria:** <100MB uso extra
- **Experiencia:** Percepción de velocidad
- **Compatibilidad:** Soporte navegadores

**Decisión:**
Virtualización con lazy loading.

**Sustento:**
Mejora métricas Core Web Vitals (LCP 1.8x mejor). Lighthouse score de 95+ en rendimiento. 

## Módulo 03: Exploración musical
### Escenario 1

| **Cod Escenario** | **Atributo de Calidad** | **Estímulo**                           | **Fuente del Estímulo** | **Artefacto**                  | **Entorno**                         | **Respuesta**                                                | **Medida de Respuesta**                             |
|------------------|-------------------------|----------------------------------------|-------------------------|--------------------------------|-------------------------------------|-------------------------------------------------------------|-----------------------------------------------------|
| ESC-EM-07 | Rendimiento | Búsqueda simultánea de 100+ usuarios | Usuarios concurrentes | Microservicio de búsqueda | Producción (pico tráfico) | Pool de conexiones optimizado y caché Redis para consultas | 95% solicitudes < 1.5s |

### Táctica Elegida
Pool de conexiones optimizado + Caché Redis (táctica ya tomada en la decisión arquitectónica del Módulo 01 — Escenario 06).

### Escenario 2

| **Cod Escenario** | **Atributo de Calidad** | **Estímulo**                           | **Fuente del Estímulo** | **Artefacto**                  | **Entorno**                         | **Respuesta**                                                | **Medida de Respuesta**                             |
|------------------|-------------------------|----------------------------------------|-------------------------|--------------------------------|-------------------------------------|-------------------------------------------------------------|-----------------------------------------------------|
| ESC-EM-08 | Rendimiento | Visualización rápida de biblioteca de usuario con +500 álbumes | Usuarios premium | Frontend React + Virtualización | Producción (uso normal) | Virtualización y lazy loading para renderizado eficiente | Render inicial < 500ms en 95% de casos |

### Táctica Elegida
Virtualización y lazy loading (React Window) (táctica ya tomada en la decisión arquitectónica del Módulo 02 — Escenario 08).

## Módulo 04: Gestión de biblioteca
### Escenario 2

| **Cod Escenario** | **Atributo de Calidad** | **Estímulo**                           | **Fuente del Estímulo** | **Artefacto**                  | **Entorno**                         | **Respuesta**                                                | **Medida de Respuesta**                             |
|------------------|-------------------------|----------------------------------------|-------------------------|--------------------------------|-------------------------------------|-------------------------------------------------------------|-----------------------------------------------------|
| ESC-GB-07 | Rendimiento | Pico de 1000+ solicitudes concurrentes de valoración | Evento de lanzamiento musical | API de valoraciones | Alta demanda | Procesamiento estable de solicitudes | Latencia <800ms en el percentil 95 |

### Tipo de decisión
Modelo de coordinación.

### Táctica Elegida
Uso de WebSockets para comunicación en tiempo real (optimiza notificaciones).

### Documentación de la Decisión (ADR)

**Título:**  
Tecnología para la comunicación en tiempo real (notificaciones de límite de valoraciones).

**Contexto:**  
Se requiere una forma de comunicar notificaciones en tiempo real desde el backend (microservicio de Gestión de Bibilioteca) al frontend (para mostrar el snack bar con los límites de valoración restantes).

**Alternativas:**
1. **WebSockets:**
    - Protocolo de comunicación bidireccional y persistente entre el navegador y el servidor.
    - Permite enviar mensajes en tiempo real sin necesidad de que el cliente realice solicitudes repetidas.
    - Ampliamente soportado por los navegadores modernos y los frameworks de backend (ej. Socket.IO, ws).

2. **Server-Sent Events (SSE):**
    - Tecnología que permite al servidor enviar eventos al navegador a través de una conexión HTTP persistente y unidireccional.
    - Más sencillo de implementar que WebSockets para la comunicación unidireccional del servidor al cliente.

3. **Polling o Long Polling:**
    - El cliente realiza solicitudes periódicas al servidor para verificar si hay nuevas notificaciones (polling) o mantiene una conexión abierta esperando una respuesta del servidor (long polling).
    - Menos eficiente que WebSockets o SSE en términos de latencia y uso de recursos.

**Criterios de elección:**
- Tiempo Real.
- Eficiencia.
- Complejidad de Implementación.
- Bidireccionalidad.

**Decisión:**
WebSockets.

**Sustento:**
WebSockets es la tecnología más adecuada para la comunicación en tiempo real bidireccional. Aunque para las notificaciones de límite de valoraciones solo se requiere comunicación del servidor al cliente, utilizar WebSockets proporciona una infraestructura flexible que podría utilizarse para otras funcionalidades en tiempo real en el futuro (si fueran necesarias). Socket.IO es una librería popular que simplifica la implementación de WebSockets, manejando automáticamente las diferentes tecnologías de transporte y proporcionando características adicionales como la reconexión automática.

### Escenario 2

| **Cod Escenario** | **Atributo de Calidad** | **Estímulo**                           | **Fuente del Estímulo** | **Artefacto**                  | **Entorno**                         | **Respuesta**                                                | **Medida de Respuesta**                             |
|------------------|-------------------------|----------------------------------------|-------------------------|--------------------------------|-------------------------------------|-------------------------------------------------------------|-----------------------------------------------------|
| ESC-EM-08 | Rendimiento | Consultas frecuentes a biblioteca de usuario | Usuarios premium activos | Base de datos MongoDB | Operación normal | Respuesta rápida de consultas | Tiempo de consulta <300ms |

### Tipo de decisión
Modelo de datos.

### Táctica Elegida
Mantenimiento de múltiples copias de datos (caché Redis) (táctica ya tomada en la decisión arquitectónica del Módulo 01 — Escenario 08).

## Módulo 05: Gestión de recomendaciones
### Escenario 1

| **Cod Escenario** | **Atributo de Calidad** | **Estímulo**                                  | **Fuente del Estímulo**   | **Artefacto**               | **Entorno**                | **Respuesta**                                                | **Medida de Respuesta**                          |
|------------------|-------------------------|-----------------------------------------------|---------------------------|----------------------------|----------------------------|-------------------------------------------------------------|-------------------------------------------------|
| ESC-GR-07    | Rendimiento             | 500 usuarios simultáneos solicitan recomendaciones personalizadas | Usuarios finales          | Módulo de recomendaciones  | Horario de alta demanda     | Responder con recomendaciones precisas en el menor tiempo posible | Tiempo de respuesta promedio < 3 segundos       |

#### Táctica Elegida
Consumo de API LLM (Hugging Face) con caché inteligente.

#### Contexto
Durante picos de uso, el sistema de recomendaciones debe procesar múltiples solicitudes concurrentes sin degradar la experiencia del usuario ni aumentar significativamente la latencia. Al utilizar Hugging Face Inference API se terceriza el cómputo pesado y se implementa una caché local (Redis) para las respuestas más frecuentes o predecibles.

#### Alternativas:

1. **Modelo propio de ML:**  
   - Requiere infraestructura costosa y mantenimiento continuo.

2. **Consumo de API LLM (Elegida):**  
   - Rápida integración vía HTTP.
   - Sin mantenimiento de modelo.
   - Permite caché local para mejorar rendimiento en consultas repetidas.

#### Criterios de elección:
- **Escalabilidad:** Soporta alta concurrencia mediante API gestionada.
- **Eficiencia:** Cache local minimiza latencia para solicitudes frecuentes.
- **Experiencia usuario:** Respuestas rápidas y coherentes.

#### Decisión
Consumo de API LLM (Hugging Face) con caché inteligente.

#### Sustento
El uso de Hugging Face Inference API elimina la necesidad de cómputo local, reduce complejidad operativa y permite escalar fácilmente según demanda. La caché local asegura tiempos de respuesta bajos incluso durante picos de carga.

## Módulo 06: Gestión de planes

### Escenario 1
| **Cod Escenario** | **Atributo de Calidad** | **Estímulo** | **Fuente del Estímulo** | **Artefacto** | **Entorno** | **Respuesta** | **Medida de Respuesta** |
|------------------|-------------------------|----------------------------------------|-------------------------|--------------------------------|-------------------------------------|-------------------------------------------------------------|-----------------------------------------------------|
| ESC-GPM-06 | Rendimiento | Alta frecuencia de consultas de verificación de permisos premium durante horas pico | Microservicios del sistema (Biblioteca, Recomendaciones, Visualización) | Sistema de verificación de permisos y cache en Redis | Operación normal con 1000+ usuarios concurrentes | El sistema responde a las consultas de permisos sin degradación del tiempo de respuesta | Tiempo de respuesta promedio menor a 50ms, capacidad para 500 consultas/segundo |

### **Táctica Elegida**
Gestionar recursos mediante mantener múltiples copias de los datos.

**Título:**  
Cache Distribuido Multi-Nivel para Verificación de Permisos.

**Contexto:**  
Los microservicios de Biblioteca, Recomendaciones y Visualización consultan constantemente el estado premium de los usuarios para habilitar funcionalidades específicas. Durante horas pico, estas consultas pueden saturar la base de datos PostgreSQL y afectar el rendimiento general del sistema.

**Alternativas:**
1. **Cache Multi-Nivel con Estrategia de Invalidación Inteligente:**
- Cache L1 en memoria de cada microservicio para consultas muy frecuentes
- Cache L2 distribuido en Redis para compartir entre microservicios
- Cache L3 de respaldo en PostgreSQL con índices optimizados
- Invalidación inteligente basada en eventos de cambio de suscripción

2. **Réplicas de Lectura con Particionamiento por Tipo de Consulta:**
- Réplica de solo lectura de PostgreSQL dedicada a consultas de permisos
- Particionamiento de datos por tipo de plan y estado de suscripción
- Balanceador de carga para distribuir consultas entre réplicas
- Sincronización asíncrona con base de datos principal

**Criterios de elección:**
- **Latencia:** Las consultas de permisos deben resolverse en menos de 50ms
- **Throughput:** Debe soportar al menos 500 consultas por segundo
- **Consistencia:** Los permisos deben reflejar el estado actual de la suscripción

**Decisión:**
Cache Multi-Nivel con Estrategia de Invalidación Inteligente.

**Sustento:**
Esta alternativa se alinea perfectamente con la decisión arquitectónica de modelo híbrido PostgreSQL + Redis con mapeo optimizado por uso. El cache multi-nivel aprovecha la infraestructura ya establecida y la invalidación inteligente garantiza consistencia de datos. Esta solución es más eficiente que las réplicas de lectura ya que mantiene los datos más frecuentemente consultados en memoria, reduciendo drasticamente la latencia y el overhead de red.

### Escenario 2
| **Cod Escenario** | **Atributo de Calidad** | **Estímulo** | **Fuente del Estímulo** | **Artefacto** | **Entorno** | **Respuesta** | **Medida de Respuesta** |
|------------------|-------------------------|----------------------------------------|-------------------------|--------------------------------|-------------------------------------|-------------------------------------------------------------|-----------------------------------------------------|
| ESC-GPM-07 | Rendimiento | Procesamiento de múltiples transacciones de pago concurrentes durante promociones especiales | Usuarios finales realizando suscripciones premium | Sistema de procesamiento de pagos con Stripe | Carga alta durante campañas promocionales | El sistema procesa todas las transacciones sin bloqueos ni timeouts | Capacidad para procesar 50 transacciones concurrentes, tiempo de respuesta menor a 3 segundos por transacción |

### **Táctica Elegida**
Gestionar recursos mediante introducir concurrencia

**Título:**  
Pool de Conexiones con Procesamiento Asíncrono de Transacciones

**Contexto:**  
Durante promociones especiales o lanzamientos de nuevas funcionalidades premium, se pueden generar picos de suscripciones que saturan el sistema de procesamiento de pagos. El procesamiento secuencial actual puede crear cuellos de botella y timeouts con la API de Stripe.

**Alternativas:**
1. **Pool de Workers Asíncronos con Cola de Transacciones:**
- Pool configurable de workers que procesan transacciones en paralelo
- Cola de transacciones en Redis con priorización por tipo de plan
- Control de concurrencia para respetar límites de rate de Stripe
- Mecanismo de backpressure para evitar sobrecarga del sistema

2. **Procesamiento Reactivo con Streams de Transacciones:**
- Implementación de streams reactivos para manejar flujo de transacciones
- Backpressure automático basado en la capacidad de procesamiento
- Paralelización automática según recursos disponibles
- Agregación de transacciones similares para optimizar llamadas a Stripe

**Criterios de elección:**
- **Escalabilidad:** Debe adaptarse automáticamente a variaciones de carga
- **Confiabilidad:** No debe perder transacciones durante picos de carga
- **Eficiencia:** Debe optimizar el uso de recursos sin desperdiciar capacidad

**Decisión:**
Pool de Workers Asíncronos con Cola de Transacciones.

**Sustento:**
Esta alternativa es consistente con la decisión arquitectónica de coordinación secuencial síncrona pero introduce concurrencia controlada donde es necesario. El pool de workers permite procesar múltiples transacciones en paralelo mientras mantiene el control sobre los límites de la API de Stripe. La cola en Redis aprovecha la infraestructura existente y el control de concurrencia garantiza que no se excedan los límites de rate limiting, manteniendo la confiabilidad del sistema.